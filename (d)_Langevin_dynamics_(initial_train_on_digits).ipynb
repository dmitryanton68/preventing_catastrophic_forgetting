{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (h) Langevin dynamics\n",
    "### Initial learning digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.cuda as cuda\n",
    "import torch.utils.data as data_utils\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "try:\n",
    "    import accimage\n",
    "except ImportError:\n",
    "    accimage = None\n",
    "\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from SpykeTorch import snn\n",
    "from SpykeTorch import functional as sf\n",
    "from SpykeTorch import visualization as vis\n",
    "from SpykeTorch import utils\n",
    "\n",
    "import struct\n",
    "import glob\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "#import import_ipynb\n",
    "#from MozafariMNIST2018_class import MozafariMNIST2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning rule\n",
    "\n",
    "class STDP(nn.Module):\n",
    "\n",
    "    def __init__(self, conv_layer, learning_rate, epsilon = 1.0, \n",
    "                 use_stabilizer = True, lower_bound = 0, upper_bound = 1):\n",
    "        \n",
    "        super(STDP, self).__init__()\n",
    "        self.conv_layer = conv_layer\n",
    "        if isinstance(learning_rate, list):\n",
    "            self.learning_rate = learning_rate\n",
    "        else:\n",
    "            self.learning_rate = [learning_rate] * conv_layer.out_channels\n",
    "        for i in range(conv_layer.out_channels):\n",
    "            self.learning_rate[i] = (Parameter(torch.tensor([self.learning_rate[i][0]])),\n",
    "                            Parameter(torch.tensor([self.learning_rate[i][1]])))\n",
    "            self.register_parameter('ltp_' + str(i), self.learning_rate[i][0])\n",
    "            self.register_parameter('ltd_' + str(i), self.learning_rate[i][1])\n",
    "            self.learning_rate[i][0].requires_grad_(False)\n",
    "            self.learning_rate[i][1].requires_grad_(False)\n",
    "        self.use_stabilizer = use_stabilizer\n",
    "        self.lower_bound = lower_bound\n",
    "        self.upper_bound = upper_bound\n",
    "        self.epsilon = epsilon  # std of weights (for Brownian dynamics in weights)\n",
    "\n",
    "    def get_pre_post_ordering(self, input_spikes, output_spikes, winners):\n",
    "        # accumulating input and output spikes to get latencies\n",
    "        input_latencies = torch.sum(input_spikes, dim=0)\n",
    "        output_latencies = torch.sum(output_spikes, dim=0)\n",
    "        result = []\n",
    "        for winner in winners:\n",
    "            # generating repeated output tensor with the same size of the receptive field\n",
    "            out_tensor = torch.ones(*self.conv_layer.kernel_size, device=output_latencies.device) * output_latencies[winner]\n",
    "            \n",
    "            # slicing input tensor with the same size of the receptive field centered around winner\n",
    "            # since there is no padding, there is no need to shift it to the center\n",
    "            in_tensor = input_latencies[:,winner[-2]:winner[-2]+self.conv_layer.kernel_size[-2],winner[-1]:winner[-1]+self.conv_layer.kernel_size[-1]]\n",
    "            result.append(torch.ge(in_tensor,out_tensor))\n",
    "        return result\n",
    "\n",
    "    # simple STDP rule with Brownian dynamics in weights\n",
    "    # gets prepost pairings, winners, weights, and learning rates (all shoud be tensors)\n",
    "    def forward(self, input_spikes, potentials, output_spikes, \n",
    "                winners=None, freeze_tensor=None, research_epoch=False, mean_value=0, \n",
    "                kwta = 1, inhibition_radius = 0):\n",
    "        \n",
    "        if winners is None:\n",
    "            winners = sf.get_k_winners(potentials, kwta, inhibition_radius, output_spikes)\n",
    "        pairings = self.get_pre_post_ordering(input_spikes, output_spikes, winners)\n",
    "\n",
    "        lr = torch.zeros_like(self.conv_layer.weight)\n",
    "        for i in range(len(winners)):\n",
    "            f = winners[i][0]\n",
    "            lr[f] = torch.where(pairings[i], *(self.learning_rate[f]))\n",
    "\n",
    "        previous_conv_layer_weight = self.conv_layer.weight.clone().detach().flatten()\n",
    "        \n",
    "        delta_weight = lr * ((self.conv_layer.weight - self.lower_bound) * \\\n",
    "                                    (self.upper_bound - self.conv_layer.weight) \\\n",
    "                                    if self.use_stabilizer else 1)\n",
    "        \n",
    "        self.conv_layer.weight += delta_weight\n",
    "        self.conv_layer.weight.clamp_(self.lower_bound, self.upper_bound)\n",
    "        \n",
    "        weights_before_noise = self.conv_layer.weight.detach().clone().flatten()\n",
    "        mean_delta_weight = weights_before_noise - previous_conv_layer_weight    # really not 'mean' \n",
    "        \n",
    "        number_unit_segment = 1111  # special number for non-research epochs\n",
    "        \n",
    "        if research_epoch:          # let's add Brownian dynamics to weights !!!!!\n",
    "            \n",
    "            number_of_features = 200\n",
    "            len_unit_segment = self.conv_layer.weight.flatten().size()[0]/number_of_features\n",
    "            nonzero_coord = torch.nonzero(delta_weight.flatten())[0].item()\n",
    "            n_u_s = int(nonzero_coord)//len_unit_segment\n",
    "\n",
    "            if isinstance(n_u_s, int) and (int(nonzero_coord)%len_unit_segment == 0):        \n",
    "                number_unit_segment = n_u_s\n",
    "            else:\n",
    "                number_unit_segment = 1000 \n",
    "            \n",
    "            mean_value = 1          # ATTENTION: because calculation of noise use only self.epsilon\n",
    "            self.conv_layer.weight += torch.normal(mean=torch.zeros_like(self.conv_layer.weight, device=\"cuda\"), \\\n",
    "                                                   std=torch.ones_like(self.conv_layer.weight, device=\"cuda\") * \\\n",
    "                                                   mean_value * self.epsilon)\n",
    "            self.conv_layer.weight.clamp_(self.lower_bound, self.upper_bound)\n",
    "            \n",
    "        return weights_before_noise, mean_delta_weight, number_unit_segment\n",
    "        \n",
    "    def update_learning_rate(self, feature, ap, an):    \n",
    "\n",
    "        self.learning_rate[feature][0][0] = ap\n",
    "        self.learning_rate[feature][1][0] = an\n",
    "\n",
    "    def update_all_learning_rate(self, ap, an):       \n",
    "    \n",
    "        for feature in range(self.conv_layer.out_channels):\n",
    "            self.learning_rate[feature][0][0] = ap\n",
    "            self.learning_rate[feature][1][0] = an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MozafariMNIST2018(nn.Module):\n",
    "    \n",
    "    def __init__(self, epsilon=2.0, dropout=0.5, dropout_procedure = False):\n",
    "        \n",
    "        super(MozafariMNIST2018, self).__init__()\n",
    "\n",
    "        self.conv1 = snn.Convolution(6, 30, 5, 0.8, 0.05)\n",
    "        self.conv1_t = 15\n",
    "        self.k1 = 5\n",
    "        self.r1 = 3\n",
    "\n",
    "        self.conv2 = snn.Convolution(30, 250, 3, 0.8, 0.05)\n",
    "        self.conv2_t = 10\n",
    "        self.k2 = 8\n",
    "        self.r2 = 1\n",
    "\n",
    "        self.conv3 = snn.Convolution(250, 200, 5, 0.8, 0.05)\n",
    "        self.number_of_features = 200\n",
    "        \n",
    "        self.dropout = dropout\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        # ATTENTION: in STDP variable epsilon - additional small value\n",
    "\n",
    "        self.stdp1 = STDP(self.conv1, (0.004, -0.003), self.epsilon)                        \n",
    "        self.stdp2 = STDP(self.conv2, (0.004, -0.003), self.epsilon)                        \n",
    "        self.stdp3 = STDP(self.conv3, (0.004, -0.003), self.epsilon, False, 0.2, 0.8)       \n",
    "        self.anti_stdp3 = STDP(self.conv3, (-0.004, 0.0005), self.epsilon, False, 0.2, 0.8) \n",
    "        self.max_ap = Parameter(torch.Tensor([0.15]))\n",
    "\n",
    "        self.decision_map = []\n",
    "        for i in range(10):\n",
    "            self.decision_map.extend([i]*20)\n",
    "\n",
    "        self.ctx = {\"input_spikes\":None, \"potentials\":None, \\\n",
    "                    \"output_spikes\":None, \"winners\":None, \\\n",
    "                    \"freeze_tensor\":None}                       # freeze_tensor was added             \n",
    "        self.spk_cnt1 = 0\n",
    "        self.spk_cnt2 = 0\n",
    "        \n",
    "        self.dropout_procedure = dropout_procedure\n",
    "        \n",
    "        \n",
    "    def forward(self, input, max_layer, mean_value=0, research_epoch=False, freeze_tensor=None):    \n",
    "        \n",
    "        input = sf.pad(input.float(), (2,2,2,2), 0)\n",
    "        \n",
    "        if self.training:\n",
    "            pot = self.conv1(input)\n",
    "            spk, pot = sf.fire(pot, self.conv1_t, True)\n",
    "            if max_layer == 1:\n",
    "                self.spk_cnt1 += 1\n",
    "                if not research_epoch:\n",
    "                    if self.spk_cnt1 >= 500:\n",
    "                        self.spk_cnt1 = 0\n",
    "                        ap = torch.tensor(self.stdp1.learning_rate[0][0].item(), device=self.stdp1.learning_rate[0][0].device) * 2\n",
    "                        ap = torch.min(ap, self.max_ap)\n",
    "                        an = ap * -0.75\n",
    "                        self.stdp1.update_all_learning_rate(ap.item(), an.item())\n",
    "                \n",
    "                pot = sf.pointwise_inhibition(pot)\n",
    "                spk = pot.sign()\n",
    "                winners = sf.get_k_winners(pot, self.k1, self.r1, spk)\n",
    "                self.ctx[\"input_spikes\"] = input\n",
    "                self.ctx[\"potentials\"] = pot\n",
    "                self.ctx[\"output_spikes\"] = spk\n",
    "                self.ctx[\"winners\"] = winners\n",
    "                return spk, pot\n",
    "            \n",
    "            spk_in = sf.pad(sf.pooling(spk, 2, 2), (1,1,1,1))\n",
    "            pot = self.conv2(spk_in)\n",
    "            spk, pot = sf.fire(pot, self.conv2_t, True)\n",
    "            if max_layer == 2:\n",
    "                self.spk_cnt2 += 1\n",
    "                if not research_epoch:\n",
    "                    if self.spk_cnt2 >= 500:\n",
    "                        self.spk_cnt2 = 0\n",
    "                        ap = torch.tensor(self.stdp2.learning_rate[0][0].item(), device=self.stdp2.learning_rate[0][0].device) * 2\n",
    "                        ap = torch.min(ap, self.max_ap)\n",
    "                        an = ap * -0.75\n",
    "                        self.stdp2.update_all_learning_rate(ap.item(), an.item())\n",
    "\n",
    "                pot = sf.pointwise_inhibition(pot)\n",
    "                spk = pot.sign()\n",
    "                winners = sf.get_k_winners(pot, self.k2, self.r2, spk)\n",
    "                self.ctx[\"input_spikes\"] = spk_in\n",
    "                self.ctx[\"potentials\"] = pot\n",
    "                self.ctx[\"output_spikes\"] = spk\n",
    "                self.ctx[\"winners\"] = winners\n",
    "                return spk, pot\n",
    "            \n",
    "            spk_in = sf.pad(sf.pooling(spk, 3, 3), (2,2,2,2))\n",
    "            pot = self.conv3(spk_in)           \n",
    "            \n",
    "            if self.dropout_procedure:\n",
    "                dropout = torch.ones(self.number_of_features) * self.dropout\n",
    "                to_be_dropped = torch.bernoulli(dropout).nonzero()   \n",
    "                sf.feature_inhibition_(pot, to_be_dropped)\n",
    "            \n",
    "            spk = sf.fire(pot)\n",
    "            winners = sf.get_k_winners(pot, 1, 0, spk)\n",
    "            self.ctx[\"input_spikes\"] = spk_in\n",
    "            self.ctx[\"potentials\"] = pot\n",
    "            self.ctx[\"output_spikes\"] = spk\n",
    "            self.ctx[\"winners\"] = winners\n",
    "            self.ctx[\"freeze_tensor\"] = freeze_tensor\n",
    "\n",
    "            output = -1\n",
    "            if len(winners) != 0:\n",
    "                output = self.decision_map[winners[0][0]]\n",
    "            return output\n",
    "        \n",
    "        else:\n",
    "            pot = self.conv1(input)\n",
    "            spk, pot = sf.fire(pot, self.conv1_t, True)\n",
    "            if max_layer == 1:\n",
    "                return spk, pot\n",
    "            \n",
    "            pot = self.conv2(sf.pad(sf.pooling(spk, 2, 2), (1,1,1,1)))\n",
    "            spk, pot = sf.fire(pot, self.conv2_t, True)\n",
    "            if max_layer == 2:\n",
    "                return spk, pot\n",
    "            pot = self.conv3(sf.pad(sf.pooling(spk, 3, 3), (2,2,2,2)))\n",
    "            spk = sf.fire(pot)\n",
    "            winners = sf.get_k_winners(pot, 1, 0, spk)\n",
    "            output = -1\n",
    "            if len(winners) != 0:\n",
    "                output = self.decision_map[winners[0][0]]\n",
    "            return output\n",
    "\n",
    "    def stdp(self, layer_idx):\n",
    "        if layer_idx == 1:\n",
    "            self.stdp1(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], \\\n",
    "                       self.ctx[\"winners\"], self.ctx[\"freeze_tensor\"], False, 0)\n",
    "        if layer_idx == 2:\n",
    "            self.stdp2(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], \\\n",
    "                       self.ctx[\"winners\"], self.ctx[\"freeze_tensor\"], False, 0)\n",
    "\n",
    "    def update_learning_rates(self, stdp_ap, stdp_an, anti_stdp_ap, anti_stdp_an):\n",
    "               \n",
    "        self.stdp3.update_all_learning_rate(stdp_ap, stdp_an)                   \n",
    "        self.anti_stdp3.update_all_learning_rate(anti_stdp_an, anti_stdp_ap)    \n",
    " \n",
    "    def reward(self, mean_value=0, research_epoch=False):\n",
    "        weights_before_noise, mean_delta_weight, number_unit_segment = self.stdp3(self.ctx[\"input_spikes\"], \\\n",
    "        self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"], self.ctx[\"freeze_tensor\"], \\\n",
    "                                                             research_epoch, mean_value)\n",
    "        return weights_before_noise, mean_delta_weight, number_unit_segment\n",
    "    \n",
    "\n",
    "    def punish(self, mean_value=0, research_epoch=False):\n",
    "        weights_before_noise, mean_delta_weight, number_unit_segment = self.anti_stdp3(self.ctx[\"input_spikes\"], \\\n",
    "        self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"], self.ctx[\"freeze_tensor\"], \\\n",
    "                                                                  research_epoch, mean_value)\n",
    "        return weights_before_noise, mean_delta_weight, number_unit_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test\n",
    "\n",
    "def train_unsupervise(network, data, layer_idx):\n",
    "    network.train()\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        data_in = data[i]\n",
    "        if use_cuda:\n",
    "            data_in = data_in.cuda()\n",
    "        network(data_in, layer_idx)\n",
    "        network.stdp(layer_idx)\n",
    "\n",
    "def train_rl(network, data, target, mean_value=0, research_epoch=False, freeze_tensor=None):\n",
    "    network.train()\n",
    "    perf = np.array([0,0,0]) # correct, wrong, silence\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        data_in = data[i]\n",
    "        target_in = target[i]\n",
    "        if use_cuda:\n",
    "            data_in = data_in.cuda()\n",
    "            target_in = target_in.cuda()\n",
    "            \n",
    "        # mean_value, research_epoch, freeze_tensor were added:\n",
    "        d = network(data_in, 3, mean_value, research_epoch, freeze_tensor)    \n",
    "        \n",
    "        if d != -1:\n",
    "            if d == target_in:\n",
    "                perf[0]+=1                \n",
    "                weights_before_noise, mean_delta_weight, reward_unit_segment = \\\n",
    "                            network.reward(mean_value, research_epoch)       \n",
    "                punish_unit_segment = 0\n",
    "            else:\n",
    "                perf[1]+=1\n",
    "                weights_before_noise, mean_delta_weight, punish_unit_segment = \\\n",
    "                            network.punish(mean_value, research_epoch) \n",
    "                reward_unit_segment = 0\n",
    "        else:\n",
    "            perf[2]+=1\n",
    "    return perf/len(data), weights_before_noise, mean_delta_weight, reward_unit_segment, punish_unit_segment\n",
    "\n",
    "def test(network, data, target):\n",
    "    network.eval()\n",
    "    perf = np.array([0,0,0]) # correct, wrong, silence\n",
    "    for i in range(len(data)):\n",
    "        data_in = data[i]\n",
    "        target_in = target[i]\n",
    "        if use_cuda:\n",
    "            data_in = data_in.cuda()\n",
    "            target_in = target_in.cuda()\n",
    "        d = network(data_in, 3)\n",
    "        if d != -1:\n",
    "            if d == target_in:\n",
    "                perf[0]+=1\n",
    "            else:\n",
    "                perf[1]+=1\n",
    "        else:\n",
    "            perf[2]+=1\n",
    "    return perf/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the 3rd layer\n",
    "\n",
    "def third_layer(file_name_net, file_name_csv, file_name_reward, file_name_punish,\n",
    "                adaptive_int, epochs, first_research_epoch, \n",
    "                train_loader, test_loader, test_previous_loader,\n",
    "                train_research_loader, model, parametr_set, epsilon):  \n",
    "    \n",
    "    '''\n",
    "    file_name_net - name of file for saving state_dict of model\n",
    "    file_name_csv - name of file for saving parameters of model in each epoch\n",
    "    adaptive_int - learning rate parameter\n",
    "    '''\n",
    "\n",
    "    begin_time = time.time()\n",
    "    \n",
    "    adaptive_min=0 \n",
    "    counter = 0\n",
    "    \n",
    "    apr = model.stdp3.learning_rate[0][0].item()\n",
    "    anr = model.stdp3.learning_rate[0][1].item()\n",
    "    app = model.anti_stdp3.learning_rate[0][1].item()\n",
    "    anp = model.anti_stdp3.learning_rate[0][0].item()\n",
    "    \n",
    "    apr_adapt = ((1.0 - 1.0 / 10) * adaptive_int + adaptive_min) * apr\n",
    "    anr_adapt = ((1.0 - 1.0 / 10) * adaptive_int + adaptive_min) * anr\n",
    "    app_adapt = ((1.0 / 10) * adaptive_int + adaptive_min) * app\n",
    "    anp_adapt = ((1.0 / 10) * adaptive_int + adaptive_min) * anp\n",
    "\n",
    "    best_train = np.array([0.0,0.0,0.0,0.0]) # correct, wrong, silence, epoch\n",
    "    best_test = np.array([0.0,0.0,0.0,0.0]) # correct, wrong, silence, epoch\n",
    "    best_test_previous = np.array([0.0,0.0,0.0,0.0]) # correct, wrong, silence, epoch\n",
    "    \n",
    "    frequency_of_recording = 100\n",
    "    \n",
    "    reward_segments_list = []\n",
    "    punish_segments_list = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        seconds_epoch_0 = time.time() \n",
    "        \n",
    "        print('-'*50)\n",
    "        print(\"Epoch #: \", epoch)\n",
    "        perf_train = np.array([0.0,0.0,0.0])\n",
    "        \n",
    "        research_epoch = False\n",
    "            \n",
    "        if epoch >= first_research_epoch:\n",
    "            research_epoch = True\n",
    "            \n",
    "        if not research_epoch:       \n",
    "\n",
    "            for data,targets in train_loader:\n",
    "\n",
    "                perf_train_batch, weights_before_noise, mean_delta_weight, _r, _p = train_rl(model, data, targets)\n",
    "\n",
    "                #update adaptive learning rates\n",
    "                apr_adapt = apr * (perf_train_batch[1] * adaptive_int + adaptive_min)\n",
    "                anr_adapt = anr * (perf_train_batch[1] * adaptive_int + adaptive_min)\n",
    "                app_adapt = app * (perf_train_batch[0] * adaptive_int + adaptive_min)\n",
    "                anp_adapt = anp * (perf_train_batch[0] * adaptive_int + adaptive_min)\n",
    "\n",
    "                parametr_set.loc[counter, 'epoch'] = epoch\n",
    "                parametr_set.loc[counter, 'train'] = perf_train_batch[0]\n",
    "\n",
    "                model.update_learning_rates(apr_adapt, anr_adapt, app_adapt, anp_adapt)\n",
    "                perf_train += perf_train_batch\n",
    "\n",
    "            perf_train /= len(train_loader)\n",
    "\n",
    "            if best_train[0] <= perf_train[0]:\n",
    "                best_train = np.append(perf_train, epoch)\n",
    "            print(f\"Current Train: {perf_train[0]*100 :.2f}%\")\n",
    "\n",
    "            for data,targets in test_loader:\n",
    "                perf_test = test(model, data, targets)\n",
    "                parametr_set.loc[counter, 'test'] = perf_test[0]\n",
    "                if best_test[0] <= perf_test[0]:\n",
    "                    best_test = np.append(perf_test, epoch)\n",
    "                    torch.save(model.state_dict(), file_name_net)\n",
    "                print(f\"Current Test: {perf_test[0]*100 :.2f}%\")\n",
    "\n",
    "            if isinstance(test_previous_loader, DataLoader):\n",
    "                for data,targets in test_previous_loader:\n",
    "                    perf_test_previous = test(model, data, targets)\n",
    "                    parametr_set.loc[counter, 'test_previous'] = perf_test_previous[0]\n",
    "                    if best_test_previous[0] <= perf_test_previous[0]:\n",
    "                        best_test_previous = np.append(perf_test_previous, epoch)\n",
    "                    print(f\"Current Test Previous: {perf_test_previous[0]*100 :.2f}%\")\n",
    "            else:\n",
    "                parametr_set.loc[counter, 'test_previous'] = 0\n",
    "\n",
    "            counter += 1\n",
    "\n",
    "            seconds_epoch_1 = time.time()  \n",
    "            print(f'Operational time of epoch #{epoch}: '\n",
    "                      f'{int((seconds_epoch_1 - seconds_epoch_0)//60)} min {int((seconds_epoch_1 - seconds_epoch_0)%60)} sec') \n",
    "\n",
    "        else:\n",
    "            print(f\"*** it's research epoch #{epoch-first_research_epoch} ***\")\n",
    "            \n",
    "            counter_of_research = 0\n",
    "            \n",
    "            unit = len(train_digit_research_loader)\n",
    "            research_tensor = torch.ones((int(unit/frequency_of_recording), \\\n",
    "                                          model.conv3.weight.flatten().size()[0]), device=device)*0   \n",
    "            \n",
    "            # for mean_delta_weight quantity of training epochs must be > 0 \n",
    "            # mean_value = torch.abs(mean_delta_weight).mean() \n",
    "            mean_value = 1\n",
    "            print(f'in N(0, std): std = epsilon = {mean_value*epsilon}')\n",
    "\n",
    "            for data, targets in train_research_loader:\n",
    "                \n",
    "                perf_train_batch, weights_before_noise, _, reward_unit_segment, punish_unit_segment = \\\n",
    "                    train_rl(model, data, targets, mean_value, research_epoch)\n",
    "                \n",
    "                reward_segments_list.append(reward_unit_segment)\n",
    "                punish_segments_list.append(punish_unit_segment)\n",
    "                \n",
    "                if counter_of_research%frequency_of_recording == 0:\n",
    "                    research_tensor[int(counter_of_research/frequency_of_recording)] = weights_before_noise\n",
    "\n",
    "                if (counter_of_research+1)%unit == 0:\n",
    "                    torch.save(research_tensor, f'set_of_weights_{epoch-first_research_epoch}.pt')\n",
    "\n",
    "                counter_of_research += 1\n",
    "                \n",
    "            for data,targets in test_loader:\n",
    "                \n",
    "                perf_test = test(model, data, targets)\n",
    "                parametr_set.loc[counter, 'train'] = 0\n",
    "                parametr_set.loc[counter, 'test'] = perf_test[0]\n",
    "                print(f\"Current Test: {perf_test[0]*100 :.2f}%\")\n",
    "            \n",
    "            counter += 1\n",
    "            \n",
    "            seconds_epoch_1 = time.time()  \n",
    "            print(f'Operational time of epoch #{epoch}: '\n",
    "                      f'{int((seconds_epoch_1 - seconds_epoch_0)//60)} min {int((seconds_epoch_1 - seconds_epoch_0)%60)} sec') \n",
    "            \n",
    "            if perf_test[0] < 0.8:\n",
    "                break\n",
    "                \n",
    "    parametr_set.to_csv(file_name_csv)\n",
    "    \n",
    "    with open(file_name_reward, 'w') as file:\n",
    "        csv.writer(file, delimiter=';').writerow(reward_segments_list)\n",
    "        \n",
    "    with open(file_name_punish, 'w') as file:\n",
    "        csv.writer(file, delimiter=';').writerow(punish_segments_list)\n",
    "\n",
    "    end_time = time.time()  \n",
    "    \n",
    "    print('=='*10, 'SUMMARY', '=='*10)\n",
    "    print(f'Total operational time: {(end_time - begin_time)//60} min')\n",
    "    if best_train[0] > 0:\n",
    "        print(f\"Best Test: {best_test[0]*100 :.2f}% on {best_test[3] :.0f} epoch\")\n",
    "        \n",
    "    return parametr_set, reward_segments_list, punish_segments_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curve_graph(parametr_set):\n",
    "\n",
    "    plt.subplots(figsize=(15, 5))\n",
    "\n",
    "    plt.plot(parametr_set['epoch'], parametr_set['train']*100, color='cyan', label='train')\n",
    "    plt.plot(parametr_set['epoch'], parametr_set['test']*100, color='blue', marker = 'o', label='test')\n",
    "    plt.plot(parametr_set['epoch'], parametr_set['test_previous']*100, linestyle = ':', color='red', label='test of previous images')\n",
    "    plt.xlabel('epochs', loc='right', fontsize=17)\n",
    "    plt.ylabel('accuracy, %',  loc='top', fontsize=17)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image transformation (see dataset)\n",
    "\n",
    "class S1C1Transform:\n",
    "    \n",
    "    def __init__(self, filter, PIL_type=False, timesteps = 15):\n",
    "        self.PIL_type = PIL_type\n",
    "        self.to_pil_image = transforms.ToPILImage()    \n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        self.filter = filter\n",
    "        self.temporal_transform = utils.Intensity2Latency(timesteps)\n",
    "        self.cnt = 0\n",
    "        \n",
    "    def __call__(self, image):\n",
    "        if self.cnt % 10000 == 0:\n",
    "            print(f'{self.cnt} images')\n",
    "        if self.PIL_type:\n",
    "            image = self.to_pil_image(image)\n",
    "        self.cnt+=1\n",
    "        image = self.to_tensor(image) * 255\n",
    "        image.unsqueeze_(0)\n",
    "        image = self.filter(image)\n",
    "        image = sf.local_normalization(image, 8)\n",
    "        temporal_image = self.temporal_transform(image)\n",
    "        return temporal_image.sign().byte()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image transformation (see dataset)\n",
    "\n",
    "kernels = [ utils.DoGKernel(3,3/9,6/9),\n",
    "            utils.DoGKernel(3,6/9,3/9),\n",
    "            utils.DoGKernel(7,7/9,14/9),\n",
    "            utils.DoGKernel(7,14/9,7/9),\n",
    "            utils.DoGKernel(13,13/9,26/9),\n",
    "            utils.DoGKernel(13,26/9,13/9)]\n",
    "\n",
    "filter = utils.Filter(kernels, padding = 6, thresholds = 50)\n",
    "\n",
    "s1c1 = S1C1Transform(filter)\n",
    "s1c1_PIL = S1C1Transform(filter, PIL_type=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image transformation (see dataset)\n",
    "\n",
    "class CustomTensorDataset(Dataset):\n",
    "    \"\"\"TensorDataset with support of transforms.\"\"\"\n",
    "    \n",
    "    def __init__(self, tensors, transform=None):\n",
    "        assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors)\n",
    "        self.tensors = tensors\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.tensors[0][index]\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        y = self.tensors[1][index]\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.tensors[0].size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set of 10 capital letters\n",
    "24000 train images + 4000 test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of 10 capital letters from EMNIST\n",
    "path = f'./data/EMNIST_own/capital_letters/'\n",
    "\n",
    "test_letter_labels = torch.load(f'{path}Mozafari_capital_letters_test_labels.pt', map_location=torch.device('cpu'))\n",
    "test_letters = torch.load(f'{path}Mozafari_capital_letters_test_images.pt', map_location=torch.device('cpu'))\n",
    "\n",
    "train_letter_labels = torch.load(f'{path}Mozafari_capital_letters_train_labels.pt', map_location=torch.device('cpu'))\n",
    "train_letters = torch.load(f'{path}Mozafari_capital_letters_train_images.pt', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element permutation\n",
    "\n",
    "train_order_l = torch.randperm(train_letter_labels.shape[0])\n",
    "test_order_l = torch.randperm(test_letter_labels.shape[0])\n",
    "\n",
    "train_letter_labels = train_letter_labels[train_order_l].view(train_letter_labels.size())\n",
    "train_letters = train_letters[train_order_l].view(train_letters.size())\n",
    "\n",
    "test_letter_labels = test_letter_labels[test_order_l].view(test_letter_labels.size())\n",
    "test_letters = test_letters[test_order_l].view(test_letters.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_letter_set = CustomTensorDataset(tensors=(train_letters, train_letter_labels), transform=s1c1_PIL)\n",
    "test_letter_set = CustomTensorDataset(tensors=(test_letters, test_letter_labels), transform=s1c1_PIL)\n",
    "\n",
    "train_letter_loader = DataLoader(train_letter_set, batch_size=len(train_letter_set))\n",
    "test_letter_loader = DataLoader(test_letter_set, batch_size=len(test_letter_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([24000]), torch.Size([4000]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_letter_labels.size(), test_letter_labels.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set of 10 MNIST digits\n",
    "Reduction 60000 train + 10000 test images to 24000 train + 4000 test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the set of 10 digit images, the same size as the set of letters (2400 trains + 400 tests per class)\n",
    "\n",
    "# the MNIST data was pre-divided into 10 classes\n",
    "path = f'./data/MNIST_0_1_2_3_4_5_6_7_8_9/'\n",
    "\n",
    "for i in classes: \n",
    "    globals()[f'train_digit_{i}_images'] = torch.load(f'{path}train_images_{i}.pt', map_location=torch.device('cpu'))[0:2400]\n",
    "    globals()[f'train_digit_{i}_labels'] = torch.load(f'{path}train_labels_{i}.pt', map_location=torch.device('cpu'))[0:2400]\n",
    "    globals()[f'test_digit_{i}_images'] = torch.load(f'{path}test_images_{i}.pt', map_location=torch.device('cpu'))[0:400]\n",
    "    globals()[f'test_digit_{i}_labels'] = torch.load(f'{path}test_labels_{i}.pt', map_location=torch.device('cpu'))[0:400]\n",
    "\n",
    "train_MNIST_labels = globals()[f'train_digit_0_labels']\n",
    "train_MNIST_images = globals()[f'train_digit_0_images']\n",
    "test_MNIST_labels = globals()[f'test_digit_0_labels']\n",
    "test_MNIST_images = globals()[f'test_digit_0_images']                                 \n",
    "\n",
    "for i in range(1, 10):\n",
    "    train_MNIST_labels = torch.cat((train_MNIST_labels, globals()[f'train_digit_{i}_labels']), 0)\n",
    "    train_MNIST_images = torch.cat((train_MNIST_images, globals()[f'train_digit_{i}_images']), 0)\n",
    "\n",
    "    test_MNIST_labels = torch.cat((test_MNIST_labels, globals()[f'test_digit_{i}_labels']), 0)\n",
    "    test_MNIST_images = torch.cat((test_MNIST_images, globals()[f'test_digit_{i}_images']), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([24000]), torch.Size([4000]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_MNIST_labels.size(), test_MNIST_labels.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element permutation\n",
    "\n",
    "train_order = torch.randperm(train_MNIST_labels.shape[0])\n",
    "test_order = torch.randperm(test_MNIST_labels.shape[0])\n",
    "\n",
    "train_MNIST_labels = train_MNIST_labels[train_order].view(train_MNIST_labels.size())\n",
    "train_MNIST_images = train_MNIST_images[train_order].view(train_MNIST_images.size())\n",
    "\n",
    "test_MNIST_labels = test_MNIST_labels[test_order].view(test_MNIST_labels.size())\n",
    "test_MNIST_images = test_MNIST_images[test_order].view(test_MNIST_images.size())\n",
    "\n",
    "train_MNIST_set = CustomTensorDataset(tensors=(train_MNIST_images, train_MNIST_labels), transform=s1c1_PIL)\n",
    "test_MNIST_set = CustomTensorDataset(tensors=(test_MNIST_images, test_MNIST_labels), transform=s1c1_PIL)\n",
    "\n",
    "train_MNIST_loader = DataLoader(train_MNIST_set, batch_size=len(train_MNIST_set))\n",
    "test_MNIST_loader = DataLoader(test_MNIST_set, batch_size=len(test_MNIST_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaders for research purpose\n",
    "\n",
    "train_MNIST_labels_r = train_MNIST_labels\n",
    "train_MNIST_images_r = train_MNIST_images\n",
    "test_MNIST_labels_r = test_MNIST_labels\n",
    "test_MNIST_images_r = test_MNIST_images\n",
    "\n",
    "train_digit_set_r = CustomTensorDataset(tensors=(train_MNIST_images_r, train_MNIST_labels_r), transform=s1c1_PIL)\n",
    "test_digit_set_r = CustomTensorDataset(tensors=(test_MNIST_images_r, test_MNIST_labels_r), transform=s1c1_PIL)\n",
    "\n",
    "train_digit_research_loader = DataLoader(train_digit_set_r, batch_size=1)\n",
    "test_digit_research_loader = DataLoader(test_digit_set_r, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epsilon is standard deviation of weights (for Brownian dynamics in weights)\n",
    "epsilon = 4e-4\n",
    "mozafari = MozafariMNIST2018(epsilon=epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n"
     ]
    }
   ],
   "source": [
    "use_cuda = True\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "    device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MozafariMNIST2018(\n",
       "  (conv1): Convolution()\n",
       "  (conv2): Convolution()\n",
       "  (conv3): Convolution()\n",
       "  (stdp1): STDP(\n",
       "    (conv_layer): Convolution()\n",
       "  )\n",
       "  (stdp2): STDP(\n",
       "    (conv_layer): Convolution()\n",
       "  )\n",
       "  (stdp3): STDP(\n",
       "    (conv_layer): Convolution()\n",
       "  )\n",
       "  (anti_stdp3): STDP(\n",
       "    (conv_layer): Convolution()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if use_cuda:\n",
    "    mozafari.cuda()   \n",
    "\n",
    "mozafari.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation of SNN trained on 24,000 images of digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file \"saved_24000_digits.net\" is the result of the file \"Initial_learning_of_SNN_on_digits.ipynb\"\n",
    "mozafari.load_state_dict(torch.load(\"saved_24000_digits.net\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametr_set = pd.DataFrame(columns=['epoch', 'train', 'test', 'test_previous'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the third layer (with Brownian dynamics in weights)\n",
    "#### only every 100th set of 3rd layer weights is recorded (240 sets per file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Epoch #:  0\n",
      "0 images\n",
      "10000 images\n",
      "20000 images\n",
      "Current Train: 96.51%\n",
      "Current Test: 93.65%\n",
      "Operational time of epoch #0: 1 min 49 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  1\n",
      "*** it's research epoch #0 ***\n",
      "in N(0, std): std = epsilon = 0.0004\n",
      "30000 images\n",
      "40000 images\n",
      "50000 images\n",
      "Current Test: 93.55%\n",
      "Operational time of epoch #1: 2 min 7 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  2\n",
      "*** it's research epoch #1 ***\n",
      "in N(0, std): std = epsilon = 0.0004\n",
      "60000 images\n",
      "70000 images\n",
      "80000 images\n",
      "Current Test: 92.73%\n",
      "Operational time of epoch #2: 2 min 7 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  3\n",
      "*** it's research epoch #2 ***\n",
      "in N(0, std): std = epsilon = 0.0004\n",
      "90000 images\n",
      "100000 images\n",
      "110000 images\n",
      "Current Test: 92.70%\n",
      "Operational time of epoch #3: 2 min 8 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  4\n",
      "*** it's research epoch #3 ***\n",
      "in N(0, std): std = epsilon = 0.0004\n",
      "120000 images\n",
      "130000 images\n",
      "Current Test: 92.42%\n",
      "Operational time of epoch #4: 2 min 8 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  5\n",
      "*** it's research epoch #4 ***\n",
      "in N(0, std): std = epsilon = 0.0004\n",
      "140000 images\n",
      "150000 images\n",
      "160000 images\n",
      "Current Test: 92.05%\n",
      "Operational time of epoch #5: 2 min 8 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  6\n",
      "*** it's research epoch #5 ***\n",
      "in N(0, std): std = epsilon = 0.0004\n",
      "170000 images\n",
      "180000 images\n",
      "190000 images\n",
      "Current Test: 92.25%\n",
      "Operational time of epoch #6: 2 min 8 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  7\n",
      "*** it's research epoch #6 ***\n",
      "in N(0, std): std = epsilon = 0.0004\n",
      "200000 images\n",
      "210000 images\n",
      "220000 images\n",
      "Current Test: 91.77%\n",
      "Operational time of epoch #7: 2 min 8 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  8\n",
      "*** it's research epoch #7 ***\n",
      "in N(0, std): std = epsilon = 0.0004\n",
      "230000 images\n",
      "240000 images\n",
      "250000 images\n",
      "Current Test: 91.83%\n",
      "Operational time of epoch #8: 2 min 9 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  9\n",
      "*** it's research epoch #8 ***\n",
      "in N(0, std): std = epsilon = 0.0004\n",
      "260000 images\n",
      "270000 images\n",
      "Current Test: 91.55%\n",
      "Operational time of epoch #9: 2 min 8 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  10\n",
      "*** it's research epoch #9 ***\n",
      "in N(0, std): std = epsilon = 0.0004\n",
      "280000 images\n",
      "290000 images\n",
      "300000 images\n",
      "Current Test: 91.50%\n",
      "Operational time of epoch #10: 2 min 8 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  11\n",
      "*** it's research epoch #10 ***\n",
      "in N(0, std): std = epsilon = 0.0004\n",
      "310000 images\n",
      "320000 images\n",
      "330000 images\n",
      "Current Test: 91.38%\n",
      "Operational time of epoch #11: 2 min 9 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  12\n",
      "*** it's research epoch #11 ***\n",
      "in N(0, std): std = epsilon = 0.0004\n",
      "340000 images\n",
      "350000 images\n",
      "360000 images\n",
      "Current Test: 90.95%\n",
      "Operational time of epoch #12: 2 min 9 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  13\n",
      "*** it's research epoch #12 ***\n",
      "in N(0, std): std = epsilon = 0.0004\n",
      "370000 images\n",
      "380000 images\n",
      "390000 images\n",
      "Current Test: 90.83%\n",
      "Operational time of epoch #13: 2 min 9 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  14\n",
      "*** it's research epoch #13 ***\n",
      "in N(0, std): std = epsilon = 0.0004\n",
      "400000 images\n",
      "410000 images\n",
      "Current Test: 90.38%\n",
      "Operational time of epoch #14: 2 min 7 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  15\n",
      "*** it's research epoch #14 ***\n",
      "in N(0, std): std = epsilon = 0.0004\n",
      "420000 images\n",
      "430000 images\n",
      "440000 images\n",
      "Current Test: 89.58%\n",
      "Operational time of epoch #15: 2 min 7 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  16\n",
      "*** it's research epoch #15 ***\n",
      "in N(0, std): std = epsilon = 0.0004\n",
      "450000 images\n",
      "460000 images\n",
      "470000 images\n",
      "Current Test: 89.45%\n",
      "Operational time of epoch #16: 2 min 7 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  17\n",
      "*** it's research epoch #16 ***\n",
      "in N(0, std): std = epsilon = 0.0004\n",
      "480000 images\n",
      "490000 images\n",
      "500000 images\n",
      "Current Test: 89.48%\n",
      "Operational time of epoch #17: 2 min 7 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  18\n",
      "*** it's research epoch #17 ***\n",
      "in N(0, std): std = epsilon = 0.0004\n",
      "510000 images\n",
      "520000 images\n",
      "530000 images\n",
      "Current Test: 88.92%\n",
      "Operational time of epoch #18: 2 min 7 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  19\n",
      "*** it's research epoch #18 ***\n",
      "in N(0, std): std = epsilon = 0.0004\n",
      "540000 images\n",
      "550000 images\n",
      "Current Test: 88.20%\n",
      "Operational time of epoch #19: 2 min 7 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  20\n",
      "*** it's research epoch #19 ***\n",
      "in N(0, std): std = epsilon = 0.0004\n",
      "560000 images\n",
      "570000 images\n",
      "580000 images\n",
      "Current Test: 88.02%\n",
      "Operational time of epoch #20: 2 min 7 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  21\n",
      "*** it's research epoch #20 ***\n",
      "in N(0, std): std = epsilon = 0.0004\n",
      "590000 images\n",
      "600000 images\n",
      "610000 images\n",
      "Current Test: 87.20%\n",
      "Operational time of epoch #21: 2 min 7 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  22\n",
      "*** it's research epoch #21 ***\n",
      "in N(0, std): std = epsilon = 0.0004\n",
      "620000 images\n",
      "630000 images\n",
      "640000 images\n",
      "Current Test: 85.95%\n",
      "Operational time of epoch #22: 2 min 7 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  23\n",
      "*** it's research epoch #22 ***\n",
      "in N(0, std): std = epsilon = 0.0004\n",
      "650000 images\n",
      "660000 images\n",
      "670000 images\n",
      "Current Test: 85.15%\n",
      "Operational time of epoch #23: 2 min 8 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  24\n",
      "*** it's research epoch #23 ***\n",
      "in N(0, std): std = epsilon = 0.0004\n",
      "680000 images\n",
      "690000 images\n",
      "Current Test: 81.50%\n",
      "Operational time of epoch #24: 2 min 8 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  25\n",
      "*** it's research epoch #24 ***\n",
      "in N(0, std): std = epsilon = 0.0004\n",
      "700000 images\n",
      "710000 images\n",
      "720000 images\n",
      "Current Test: 78.17%\n",
      "Operational time of epoch #25: 2 min 8 sec\n",
      "==================== SUMMARY ====================\n",
      "Total operational time: 55.0 min\n",
      "Best Test: 93.65% on 0 epoch\n"
     ]
    }
   ],
   "source": [
    "first_test = third_layer(file_name_net=\"saved_digits_research.net\",\n",
    "                        file_name_csv='parameter_set_digits_research.csv',\n",
    "                        file_name_reward='reward_segments_list.csv', \n",
    "                        file_name_punish='punish_segments_list.csv',  \n",
    "                        adaptive_int=0.5, epochs=101, first_research_epoch=1,\n",
    "                        train_loader=train_MNIST_loader, test_loader=test_MNIST_loader, test_previous_loader=[],\n",
    "                        train_research_loader=train_digit_research_loader, \n",
    "                        model=mozafari, parametr_set=parametr_set, epsilon=epsilon)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
