{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (i) Joint training\n",
    "### Learning letters + digits after learning digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.cuda as cuda\n",
    "import torch.utils.data as data_utils\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "try:\n",
    "    import accimage\n",
    "except ImportError:\n",
    "    accimage = None\n",
    "\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from SpykeTorch import snn\n",
    "from SpykeTorch import functional as sf\n",
    "from SpykeTorch import visualization as vis\n",
    "from SpykeTorch import utils\n",
    "\n",
    "import struct\n",
    "import glob\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "class MozafariMNIST2018(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(MozafariMNIST2018, self).__init__()\n",
    "\n",
    "        self.conv1 = snn.Convolution(6, 30, 5, 0.8, 0.05)\n",
    "        self.conv1_t = 15\n",
    "        self.k1 = 5\n",
    "        self.r1 = 3\n",
    "\n",
    "        self.conv2 = snn.Convolution(30, 250, 3, 0.8, 0.05)\n",
    "        self.conv2_t = 10\n",
    "        self.k2 = 8\n",
    "        self.r2 = 1\n",
    "\n",
    "        self.conv3 = snn.Convolution(250, 200, 5, 0.8, 0.05)\n",
    "\n",
    "        self.stdp1 = snn.STDP(self.conv1, (0.004, -0.003))\n",
    "        self.stdp2 = snn.STDP(self.conv2, (0.004, -0.003))\n",
    "        self.stdp3 = snn.STDP(self.conv3, (0.004, -0.003), False, 0.2, 0.8)\n",
    "        self.anti_stdp3 = snn.STDP(self.conv3, (-0.004, 0.0005), False, 0.2, 0.8)\n",
    "        self.max_ap = Parameter(torch.Tensor([0.15]))\n",
    "\n",
    "        self.decision_map = []\n",
    "        for i in range(10):\n",
    "            self.decision_map.extend([i]*20)\n",
    "\n",
    "        self.ctx = {\"input_spikes\":None, \"potentials\":None, \"output_spikes\":None, \"winners\":None}\n",
    "        self.spk_cnt1 = 0\n",
    "        self.spk_cnt2 = 0\n",
    "\n",
    "    def forward(self, input, max_layer):\n",
    "        \n",
    "        input = sf.pad(input.float(), (2,2,2,2), 0)\n",
    "        \n",
    "        if self.training:\n",
    "            pot = self.conv1(input)\n",
    "            spk, pot = sf.fire(pot, self.conv1_t, True)\n",
    "            if max_layer == 1:\n",
    "                self.spk_cnt1 += 1\n",
    "                if self.spk_cnt1 >= 500:\n",
    "                    self.spk_cnt1 = 0\n",
    "                    ap = torch.tensor(self.stdp1.learning_rate[0][0].item(), device=self.stdp1.learning_rate[0][0].device) * 2\n",
    "                    ap = torch.min(ap, self.max_ap)\n",
    "                    an = ap * -0.75\n",
    "                    self.stdp1.update_all_learning_rate(ap.item(), an.item())\n",
    "                pot = sf.pointwise_inhibition(pot)\n",
    "                spk = pot.sign()\n",
    "                winners = sf.get_k_winners(pot, self.k1, self.r1, spk)\n",
    "                self.ctx[\"input_spikes\"] = input\n",
    "                self.ctx[\"potentials\"] = pot\n",
    "                self.ctx[\"output_spikes\"] = spk\n",
    "                self.ctx[\"winners\"] = winners\n",
    "                return spk, pot\n",
    "            \n",
    "            spk_in = sf.pad(sf.pooling(spk, 2, 2), (1,1,1,1))\n",
    "            pot = self.conv2(spk_in)\n",
    "            spk, pot = sf.fire(pot, self.conv2_t, True)\n",
    "            if max_layer == 2:\n",
    "                self.spk_cnt2 += 1\n",
    "                if self.spk_cnt2 >= 500:\n",
    "                    self.spk_cnt2 = 0\n",
    "                    ap = torch.tensor(self.stdp2.learning_rate[0][0].item(), device=self.stdp2.learning_rate[0][0].device) * 2\n",
    "                    ap = torch.min(ap, self.max_ap)\n",
    "                    an = ap * -0.75\n",
    "                    self.stdp2.update_all_learning_rate(ap.item(), an.item())\n",
    "                pot = sf.pointwise_inhibition(pot)\n",
    "                spk = pot.sign()\n",
    "                winners = sf.get_k_winners(pot, self.k2, self.r2, spk)\n",
    "                self.ctx[\"input_spikes\"] = spk_in\n",
    "                self.ctx[\"potentials\"] = pot\n",
    "                self.ctx[\"output_spikes\"] = spk\n",
    "                self.ctx[\"winners\"] = winners\n",
    "                return spk, pot\n",
    "            \n",
    "            spk_in = sf.pad(sf.pooling(spk, 3, 3), (2,2,2,2))\n",
    "            pot = self.conv3(spk_in)\n",
    "            spk = sf.fire(pot)\n",
    "            winners = sf.get_k_winners(pot, 1, 0, spk)\n",
    "            self.ctx[\"input_spikes\"] = spk_in\n",
    "            self.ctx[\"potentials\"] = pot\n",
    "            self.ctx[\"output_spikes\"] = spk\n",
    "            self.ctx[\"winners\"] = winners\n",
    "            output = -1\n",
    "            if len(winners) != 0:\n",
    "                output = self.decision_map[winners[0][0]]\n",
    "            return output\n",
    "        \n",
    "        else:\n",
    "            pot = self.conv1(input)\n",
    "            spk, pot = sf.fire(pot, self.conv1_t, True)\n",
    "            if max_layer == 1:\n",
    "                return spk, pot\n",
    "            \n",
    "            pot = self.conv2(sf.pad(sf.pooling(spk, 2, 2), (1,1,1,1)))\n",
    "            spk, pot = sf.fire(pot, self.conv2_t, True)\n",
    "            if max_layer == 2:\n",
    "                return spk, pot\n",
    "            pot = self.conv3(sf.pad(sf.pooling(spk, 3, 3), (2,2,2,2)))\n",
    "            spk = sf.fire(pot)\n",
    "            winners = sf.get_k_winners(pot, 1, 0, spk)\n",
    "            output = -1\n",
    "            if len(winners) != 0:\n",
    "                output = self.decision_map[winners[0][0]]\n",
    "            return output\n",
    "\n",
    "    def stdp(self, layer_idx):\n",
    "        if layer_idx == 1:\n",
    "            self.stdp1(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
    "        if layer_idx == 2:\n",
    "            self.stdp2(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
    "\n",
    "    def update_learning_rates(self, stdp_ap, stdp_an, anti_stdp_ap, anti_stdp_an):\n",
    "        self.stdp3.update_all_learning_rate(stdp_ap, stdp_an)\n",
    "        self.anti_stdp3.update_all_learning_rate(anti_stdp_an, anti_stdp_ap)\n",
    "\n",
    "    def reward(self):\n",
    "        self.stdp3(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n",
    "\n",
    "    def punish(self):\n",
    "        self.anti_stdp3(self.ctx[\"input_spikes\"], self.ctx[\"potentials\"], self.ctx[\"output_spikes\"], self.ctx[\"winners\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test\n",
    "\n",
    "def train_unsupervise(network, data, layer_idx):\n",
    "    network.train()\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        data_in = data[i]\n",
    "        if use_cuda:\n",
    "            data_in = data_in.cuda()\n",
    "        network(data_in, layer_idx)\n",
    "        network.stdp(layer_idx)\n",
    "\n",
    "def train_rl(network, data, target):\n",
    "    network.train()\n",
    "    perf = np.array([0,0,0]) # correct, wrong, silence\n",
    "    for i in range(len(data)):\n",
    "        data_in = data[i]\n",
    "        target_in = target[i]\n",
    "        if use_cuda:\n",
    "            data_in = data_in.cuda()\n",
    "            target_in = target_in.cuda()\n",
    "        d = network(data_in, 3)\n",
    "        if d != -1:\n",
    "            if d == target_in:\n",
    "                perf[0]+=1\n",
    "                network.reward()\n",
    "            else:\n",
    "                perf[1]+=1\n",
    "                network.punish()\n",
    "        else:\n",
    "            perf[2]+=1\n",
    "    return perf/len(data)\n",
    "\n",
    "def test(network, data, target):\n",
    "    network.eval()\n",
    "    perf = np.array([0,0,0]) # correct, wrong, silence\n",
    "    for i in range(len(data)):\n",
    "        data_in = data[i]\n",
    "        target_in = target[i]\n",
    "        if use_cuda:\n",
    "            data_in = data_in.cuda()\n",
    "            target_in = target_in.cuda()\n",
    "        d = network(data_in, 3)\n",
    "        if d != -1:\n",
    "            if d == target_in:\n",
    "                perf[0]+=1\n",
    "            else:\n",
    "                perf[1]+=1\n",
    "        else:\n",
    "            perf[2]+=1\n",
    "    return perf/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curve_graph(parametr_set):\n",
    "\n",
    "    plt.subplots(figsize=(15, 5))\n",
    "\n",
    "    plt.plot(parametr_set['epoch'], parametr_set['train']*100, color='cyan', label='train')\n",
    "    plt.plot(parametr_set['epoch'], parametr_set['test']*100, color='blue', marker = 'o', label='test')\n",
    "    plt.plot(parametr_set['epoch'], parametr_set['test_previous']*100, linestyle = ':', color='red', label='test of previous images')\n",
    "    plt.xlabel('epochs', loc='right', fontsize=17)\n",
    "    plt.ylabel('accuracy, %',  loc='top', fontsize=17)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train of 3-rd layer\n",
    "\n",
    "def third_layer(file_name_net, file_name_csv, adaptive_int, previous_epochs, epochs, \n",
    "                train_loader, test_loader, test_previous_loader,\n",
    "                model, apr, anr, app, anp, parametr_set, \n",
    "                steps=None, percent=20, value_for_moved_weights=0.8,\n",
    "                it_continues=False, freeze_procedure=False):  \n",
    "    \n",
    "    '''\n",
    "    file_name_net - name of file for saving state_dict of model\n",
    "    file_name_csv - name of file for saving parameters of model in each epoch\n",
    "    adaptive_int - learning rate parameter\n",
    "    previous_epochs - if before model had training in current period\n",
    "    it_continues - is it continue of 3-rd layer training or not (False or True)\n",
    "    percent - percent of moving weights (calculated from the number of high range weights)\n",
    "    '''\n",
    "\n",
    "    adaptive_min=0 \n",
    "\n",
    "    if not it_continues:\n",
    "\n",
    "        previous_epochs = 0\n",
    "        counter = 0\n",
    "\n",
    "        apr_adapt = ((1.0 - 1.0 / 10) * adaptive_int + adaptive_min) * apr\n",
    "        anr_adapt = ((1.0 - 1.0 / 10) * adaptive_int + adaptive_min) * anr\n",
    "        app_adapt = ((1.0 / 10) * adaptive_int + adaptive_min) * app\n",
    "        anp_adapt = ((1.0 / 10) * adaptive_int + adaptive_min) * anp\n",
    "        \n",
    "        best_train = np.array([0.0,0.0,0.0,0.0]) # correct, wrong, silence, epoch\n",
    "        best_test = np.array([0.0,0.0,0.0,0.0]) # correct, wrong, silence, epoch\n",
    "        best_test_previous = np.array([0.0,0.0,0.0,0.0]) # correct, wrong, silence, epoch\n",
    "\n",
    "    else:\n",
    "      \n",
    "        if len(parametr_set.loc[parametr_set['test'] == parametr_set['test'].max(), 'epoch']) == 1:\n",
    "            optim_index = int(parametr_set.loc[parametr_set['test'] == parametr_set['test'].max(), 'epoch'].item())\n",
    "        else:\n",
    "            optim_index = int(parametr_set.loc[parametr_set['test'] == parametr_set['test'].max(), 'epoch'].tolist()[-1])\n",
    "\n",
    "        if len(parametr_set.loc[parametr_set['train'] == parametr_set['train'].max(), 'epoch']) == 1:\n",
    "            best_train_index = int(parametr_set.loc[parametr_set['train'] == parametr_set['train'].max(), 'epoch'].item())\n",
    "        else:\n",
    "            best_train_index = int(parametr_set.loc[parametr_set['train'] == parametr_set['train'].max(), 'epoch'].tolist()[-1])\n",
    "\n",
    "        if len(parametr_set.loc[parametr_set['test_previous'] == parametr_set['test_previous'].max(), 'epoch']) == 1:\n",
    "            best_test_previous_index = int(parametr_set.loc[parametr_set['test_previous'] == parametr_set['test_previous'].max(), 'epoch'].item())\n",
    "        else:\n",
    "            best_test_previous_index = int(parametr_set.loc[parametr_set['test_previous'] == parametr_set['test_previous'].max(), 'epoch'].tolist()[-1])\n",
    "        \n",
    "        max_index = int(parametr_set.index.max())\n",
    "        counter = (max_index + 1)\n",
    "\n",
    "        param_best_train = parametr_set['train'].iloc[best_train_index]\n",
    "        param_best_test = parametr_set['test'].iloc[optim_index]\n",
    "        param_best_test_previous = parametr_set['test_previous'].iloc[best_test_previous_index]\n",
    "\n",
    "        apr_adapt = parametr_set['apr_adapt'].iloc[optim_index]\n",
    "        anr_adapt = parametr_set['anr_adapt'].iloc[optim_index]\n",
    "        app_adapt = parametr_set['app_adapt'].iloc[optim_index]\n",
    "        anp_adapt = parametr_set['anp_adapt'].iloc[optim_index]\n",
    "        \n",
    "        for i in range(len(model.stdp3.learning_rate)):\n",
    "            model.stdp3.learning_rate[i][0].fill_(parametr_set['stdp3.learning_rate[0]'].iloc[optim_index])\n",
    "            model.stdp3.learning_rate[i][1].fill_(parametr_set['stdp3.learning_rate[1]'].iloc[optim_index])\n",
    "            model.anti_stdp3.learning_rate[0][0].fill_(parametr_set['anti_stdp3.learning_rate[0]'].iloc[optim_index])\n",
    "            model.anti_stdp3.learning_rate[0][0].fill_(parametr_set['anti_stdp3.learning_rate[1]'].iloc[optim_index])\n",
    "\n",
    "        best_train = np.array([param_best_train,1-param_best_train,0.0,best_train_index]) # correct, wrong, silence, epoch\n",
    "        best_test = np.array([param_best_test,1-param_best_test,0.0,optim_index]) # correct, wrong, silence, epoch\n",
    "        best_test_previous = np.array([param_best_test_previous,1-param_best_test_previous,0.0,best_test_previous_index]) # correct, wrong, silence, epoch\n",
    "    \n",
    "    # list of 3-rd layer weights\n",
    "\n",
    "    dim_0, dim_1, dim_2, dim_3 = tuple(model.conv3.weight.size())\n",
    "    total_size = dim_0 * dim_1 * dim_2 * dim_3\n",
    "  \n",
    "    # indexes of weights\n",
    "    indexes_i = []    \n",
    "    indexes_j = []        \n",
    "    indexes_k = []        \n",
    "    indexes_m = []    \n",
    "    \n",
    "    # values of weights\n",
    "    item_values = []  \n",
    "    \n",
    "    for i in range(dim_0):\n",
    "        for j in range(dim_1):\n",
    "            for k in range(dim_2):\n",
    "                for m in range(dim_3):\n",
    "                    indexes_i.append(i)\n",
    "                    indexes_j.append(j)\n",
    "                    indexes_k.append(k)\n",
    "                    indexes_m.append(m)\n",
    "                    item_values.append(model.conv3.weight[i][j][k][m].item())\n",
    "\n",
    "    indexes_dim_0 = pd.Series(indexes_i, name='dim_0') \n",
    "    indexes_dim_1 = pd.Series(indexes_j, name='dim_1')\n",
    "    indexes_dim_2 = pd.Series(indexes_k, name='dim_2')\n",
    "    indexes_dim_3 = pd.Series(indexes_m, name='dim_3')\n",
    "    item_values = pd.Series(item_values, name='value_0')\n",
    "            \n",
    "    conv3_data = pd.concat([item_values, indexes_dim_0, indexes_dim_1, indexes_dim_2, indexes_dim_3], axis=1)\n",
    "    \n",
    "    high_percent = 85 #percent of high range weights\n",
    "    percentile_value = np.percentile(item_values, high_percent)\n",
    "    \n",
    "    conv3_data['low_range_0'] = 0\n",
    "    conv3_data.loc[conv3_data['value_0'] < percentile_value,'low_range_0'] = 1\n",
    "    \n",
    "    # indexes of freeze weights of third layer before training on the next set                   \n",
    "    conv3_data['freeze_weights'] = 0\n",
    "    conv3_data.loc[conv3_data['value_0'] > percentile_value,'freeze_weights'] = 1      \n",
    "    \n",
    "    if freeze_procedure:\n",
    "        print(f\"During training {conv3_data['freeze_weights'].sum()} weights \"\n",
    "              f\"({conv3_data['freeze_weights'].sum()/total_size*100 :.1f}%) will be freezed\")\n",
    "        \n",
    "        weights_threshold = nn.Threshold(percentile_value, 0)\n",
    "        freeze_tensor = weights_threshold(model.conv3.weight)                     \n",
    "        freeze_list = conv3_data.loc[conv3_data['freeze_weights'] == 1, 'value_0'].to_numpy()\n",
    "    else:\n",
    "        freeze_list=[]\n",
    "        freeze_tensor=None\n",
    "\n",
    "    try:\n",
    "        high_range_counter = conv3_data['low_range_0'].value_counts()[0] \n",
    "    except:\n",
    "        high_range_counter = 1\n",
    " \n",
    "    moving_quantity = int((percent/100)*high_range_counter)      #quantity of moving items in each epoch\n",
    "    #quantity of moving items in each epoch is calculated without taking in account freezed weights\n",
    "    \n",
    "    if steps is None:\n",
    "        steps = int(total_size*high_percent/(100*moving_quantity))   #steps of weights moving \n",
    "    elif steps == 0:\n",
    "        print(f'Training will be performed without weight moving.')\n",
    "    else:\n",
    "        print(f'Weight moving will be during {steps} epochs')\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        seconds_epoch_0 = time.time() \n",
    "        \n",
    "        print('-'*50)\n",
    "        print(\"Epoch #: \", epoch + previous_epochs)\n",
    "        \n",
    "        perf_train = np.array([0.0,0.0,0.0]) \n",
    "        \n",
    "        for data,targets in train_loader:\n",
    "                \n",
    "            if epoch < steps: \n",
    "                \n",
    "                print(f'Values of high range weights in epoch#{epoch} [{percentile_value :.3f}:0.800] (top {100-high_percent}%)')\n",
    "                low_range_indexes = list(conv3_data.index[(conv3_data['low_range_'+str(epoch)] == 1)&(conv3_data['freeze_weights'] == 0)])\n",
    "                moving_items = random.sample(low_range_indexes, np.minimum(moving_quantity, len(low_range_indexes)))\n",
    "                moving_indexes = conv3_data.loc[conv3_data.index.isin(moving_items)]\n",
    "\n",
    "                print(f'Quantity of moving points in epoch#{epoch + previous_epochs} = {len(moving_indexes.index)} items' \n",
    "                      f' ({len(moving_indexes.index)/(total_size-high_range_counter)*100 :.1f}% of moving points)')\n",
    "\n",
    "                for q in range(len(moving_indexes.index)):\n",
    "                    model.conv3.weight \\\n",
    "                    [moving_indexes['dim_0'].iloc[q]][moving_indexes['dim_1'].iloc[q]][moving_indexes['dim_2'].iloc[q]][moving_indexes['dim_3'].iloc[q]]. \\\n",
    "                    fill_(np.random.normal(loc=value_for_moved_weights, scale=0.05))  \n",
    "                \n",
    "            perf_train_batch = train_rl(model, data, targets)        \n",
    "    \n",
    "            if epoch < steps:  \n",
    "            \n",
    "                # new values of weights (after learning)\n",
    "                item_values = []       \n",
    "                for i in range(dim_0):\n",
    "                    for j in range(dim_1):\n",
    "                        for k in range(dim_2):\n",
    "                            for m in range(dim_3):\n",
    "                                item_values.append(model.conv3.weight[i][j][k][m].item())\n",
    "            \n",
    "                item_values = pd.Series(item_values, name='value_'+str(epoch+1))\n",
    "                percentile_value = np.percentile(item_values, high_percent) #new cutting off high range weights\n",
    "                conv3_data = pd.concat([conv3_data, item_values], axis=1)\n",
    "                \n",
    "                conv3_data['low_range_'+str(epoch+1)] = 0\n",
    "                conv3_data.loc[conv3_data['value_'+str(epoch+1)] < percentile_value,'low_range_'+str(epoch+1)] = 1\n",
    "       \n",
    "            #update adaptive learning rates\n",
    "            apr_adapt = apr * (perf_train_batch[1] * adaptive_int + adaptive_min)\n",
    "            anr_adapt = anr * (perf_train_batch[1] * adaptive_int + adaptive_min)\n",
    "            app_adapt = app * (perf_train_batch[0] * adaptive_int + adaptive_min)\n",
    "            anp_adapt = anp * (perf_train_batch[0] * adaptive_int + adaptive_min)\n",
    "            parametr_set.loc[counter, 'epoch'] = epoch + previous_epochs\n",
    "            parametr_set.loc[counter, 'apr_adapt'] = apr_adapt\n",
    "            parametr_set.loc[counter, 'anr_adapt'] = anr_adapt\n",
    "            parametr_set.loc[counter, 'app_adapt'] = app_adapt\n",
    "            parametr_set.loc[counter, 'anp_adapt'] = anp_adapt\n",
    "            parametr_set.loc[counter, 'stdp3.learning_rate[0]'] = model.stdp3.learning_rate[0][0].item()\n",
    "            parametr_set.loc[counter, 'stdp3.learning_rate[1]'] = model.stdp3.learning_rate[0][1].item()\n",
    "            parametr_set.loc[counter, 'anti_stdp3.learning_rate[0]'] = model.anti_stdp3.learning_rate[0][0].item()\n",
    "            parametr_set.loc[counter, 'anti_stdp3.learning_rate[1]'] = model.anti_stdp3.learning_rate[0][1].item()\n",
    "            parametr_set.loc[counter, 'train'] = perf_train_batch[0]\n",
    "\n",
    "            model.update_learning_rates(apr_adapt, anr_adapt, app_adapt, anp_adapt)\n",
    "            perf_train += perf_train_batch\n",
    "            \n",
    "        perf_train /= len(train_loader)\n",
    "\n",
    "        if best_train[0] <= perf_train[0]:\n",
    "            best_train = np.append(perf_train, epoch + previous_epochs)\n",
    "        print(f\"Current Train: {perf_train[0]*100 :.2f}%\")\n",
    "        #print(\"   Best Train:\", best_train)\n",
    "\n",
    "        for data,targets in test_loader:\n",
    "            perf_test = test(model, data, targets)\n",
    "            parametr_set.loc[counter, 'test'] = perf_test[0]\n",
    "            if best_test[0] <= perf_test[0]:\n",
    "                best_test = np.append(perf_test, epoch + previous_epochs)\n",
    "                torch.save(model.state_dict(), file_name_net)\n",
    "            print(f\"Current Test: {perf_test[0]*100 :.2f}%\")\n",
    "            #print(\"    Best Test:\", best_test)\n",
    "\n",
    "        if isinstance(test_previous_loader, DataLoader):\n",
    "            for data,targets in test_previous_loader:\n",
    "                perf_test_previous = test(model, data, targets)\n",
    "                parametr_set.loc[counter, 'test_previous'] = perf_test_previous[0]\n",
    "                if best_test_previous[0] <= perf_test_previous[0]:\n",
    "                    best_test_previous = np.append(perf_test_previous, epoch + previous_epochs)\n",
    "                print(f\"Current Test Previous: {perf_test_previous[0]*100 :.2f}%\")\n",
    "                #print(\"    Best Test Previous:\", best_test_previous)\n",
    "                \n",
    "        else:\n",
    "            parametr_set.loc[counter, 'test_previous'] = 0\n",
    "            \n",
    "        counter += 1\n",
    "                                                 \n",
    "        seconds_epoch_1 = time.time()  \n",
    "        print(f'Operational time of epoch #{epoch + previous_epochs}: '\n",
    "                  f'{int((seconds_epoch_1 - seconds_epoch_0)//60)} min {int((seconds_epoch_1 - seconds_epoch_0)%60)} sec') \n",
    "    \n",
    "    parametr_set.to_csv(file_name_csv)\n",
    "    \n",
    "    print('=='*10, 'SUMMARY', '=='*10)\n",
    "    print(f\"        Best Train: {best_train[0]*100 :.2f}% on {best_train[3] :.0f} epoch\")\n",
    "    print(f\"         Best Test: {best_test[0]*100 :.2f}% on {best_test[3] :.0f} epoch\")\n",
    "    print(f\"Best Test Previous: {best_test_previous[0]*100 :.2f}% on {best_test_previous[3] :.0f} epoch\")\n",
    "    \n",
    "    return parametr_set, counter, (previous_epochs+epochs), apr, anr, app, anp, conv3_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image transformation (see dataset)\n",
    "\n",
    "class S1C1Transform:\n",
    "    \n",
    "    def __init__(self, filter, PIL_type=False, timesteps = 15):\n",
    "        self.PIL_type = PIL_type\n",
    "        self.to_pil_image = transforms.ToPILImage()    \n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        self.filter = filter\n",
    "        self.temporal_transform = utils.Intensity2Latency(timesteps)\n",
    "        self.cnt = 0\n",
    "        \n",
    "    def __call__(self, image):\n",
    "        if self.cnt % 10000 == 0:\n",
    "            print(f'{self.cnt} images')\n",
    "        if self.PIL_type:\n",
    "            image = self.to_pil_image(image)\n",
    "        self.cnt+=1\n",
    "        image = self.to_tensor(image) * 255\n",
    "        image.unsqueeze_(0)\n",
    "        image = self.filter(image)\n",
    "        image = sf.local_normalization(image, 8)\n",
    "        temporal_image = self.temporal_transform(image)\n",
    "        return temporal_image.sign().byte()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image transformation (see dataset)\n",
    "\n",
    "kernels = [ utils.DoGKernel(3,3/9,6/9),\n",
    "            utils.DoGKernel(3,6/9,3/9),\n",
    "            utils.DoGKernel(7,7/9,14/9),\n",
    "            utils.DoGKernel(7,14/9,7/9),\n",
    "            utils.DoGKernel(13,13/9,26/9),\n",
    "            utils.DoGKernel(13,26/9,13/9)]\n",
    "\n",
    "filter = utils.Filter(kernels, padding = 6, thresholds = 50)\n",
    "\n",
    "s1c1 = S1C1Transform(filter)\n",
    "s1c1_PIL = S1C1Transform(filter, PIL_type=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image transformation (see dataset)\n",
    "\n",
    "class CustomTensorDataset(Dataset):\n",
    "    \"\"\"TensorDataset with support of transforms.\"\"\"\n",
    "    \n",
    "    def __init__(self, tensors, transform=None):\n",
    "        assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors)\n",
    "        self.tensors = tensors\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.tensors[0][index]\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        y = self.tensors[1][index]\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.tensors[0].size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set of 10 capital letters\n",
    "24000 train images + 4000 test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of 10 capital letters from EMNIST\n",
    "\n",
    "path = f'./data/EMNIST_own/capital_letters/'\n",
    "\n",
    "test_letter_labels = torch.load(f'{path}Mozafari_capital_letters_test_labels.pt', map_location=torch.device('cpu'))\n",
    "test_letters = torch.load(f'{path}Mozafari_capital_letters_test_images.pt', map_location=torch.device('cpu'))\n",
    "\n",
    "train_letter_labels = torch.load(f'{path}Mozafari_capital_letters_train_labels.pt', map_location=torch.device('cpu'))\n",
    "train_letters = torch.load(f'{path}Mozafari_capital_letters_train_images.pt', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element permutation\n",
    "\n",
    "train_order_l = torch.randperm(train_letter_labels.shape[0])\n",
    "test_order_l = torch.randperm(test_letter_labels.shape[0])\n",
    "\n",
    "train_letter_labels = train_letter_labels[train_order_l].view(train_letter_labels.size())\n",
    "train_letters = train_letters[train_order_l].view(train_letters.size())\n",
    "\n",
    "test_letter_labels = test_letter_labels[test_order_l].view(test_letter_labels.size())\n",
    "test_letters = test_letters[test_order_l].view(test_letters.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([24000]), torch.Size([4000]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_letter_labels.size(), test_letter_labels.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_letter_set = CustomTensorDataset(tensors=(train_letters, train_letter_labels), transform=s1c1_PIL)\n",
    "test_letter_set = CustomTensorDataset(tensors=(test_letters, test_letter_labels), transform=s1c1_PIL)\n",
    "\n",
    "train_letter_loader = DataLoader(train_letter_set, batch_size=len(train_letter_set))\n",
    "test_letter_loader = DataLoader(test_letter_set, batch_size=len(test_letter_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set of 10 MNIST digits\n",
    "Reduction the set of 60000 train + 10000 test images to the set of 24000 train + 4000 test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the set of 10 digit images, the same size as the set of letters (2400 trains + 400 tests per class)\n",
    "# the MNIST data was pre-divided into 10 classes\n",
    "path = f'./data/MNIST_0_1_2_3_4_5_6_7_8_9/'\n",
    "\n",
    "for i in classes: \n",
    "    globals()[f'train_digit_{i}_images'] = torch.load(f'{path}train_images_{i}.pt', map_location=torch.device('cpu'))[0:2400]\n",
    "    globals()[f'train_digit_{i}_labels'] = torch.load(f'{path}train_labels_{i}.pt', map_location=torch.device('cpu'))[0:2400]\n",
    "    globals()[f'test_digit_{i}_images'] = torch.load(f'{path}test_images_{i}.pt', map_location=torch.device('cpu'))[0:400]\n",
    "    globals()[f'test_digit_{i}_labels'] = torch.load(f'{path}test_labels_{i}.pt', map_location=torch.device('cpu'))[0:400]\n",
    "\n",
    "train_MNIST_labels = globals()[f'train_digit_0_labels']\n",
    "train_MNIST_images = globals()[f'train_digit_0_images']\n",
    "test_MNIST_labels = globals()[f'test_digit_0_labels']\n",
    "test_MNIST_images = globals()[f'test_digit_0_images']                                 \n",
    "\n",
    "for i in range(1, 10):\n",
    "    train_MNIST_labels = torch.cat((train_MNIST_labels, globals()[f'train_digit_{i}_labels']), 0)\n",
    "    train_MNIST_images = torch.cat((train_MNIST_images, globals()[f'train_digit_{i}_images']), 0)\n",
    "\n",
    "    test_MNIST_labels = torch.cat((test_MNIST_labels, globals()[f'test_digit_{i}_labels']), 0)\n",
    "    test_MNIST_images = torch.cat((test_MNIST_images, globals()[f'test_digit_{i}_images']), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([24000]), torch.Size([4000]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_MNIST_labels.size(), test_MNIST_labels.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element permutation\n",
    "\n",
    "train_order = torch.randperm(train_MNIST_labels.shape[0])\n",
    "test_order = torch.randperm(test_MNIST_labels.shape[0])\n",
    "\n",
    "train_MNIST_labels = train_MNIST_labels[train_order].view(train_MNIST_labels.size())\n",
    "train_MNIST_images = train_MNIST_images[train_order].view(train_MNIST_images.size())\n",
    "\n",
    "test_MNIST_labels = test_MNIST_labels[test_order].view(test_MNIST_labels.size())\n",
    "test_MNIST_images = test_MNIST_images[test_order].view(test_MNIST_images.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_MNIST_set = CustomTensorDataset(tensors=(train_MNIST_images, train_MNIST_labels), transform=s1c1_PIL)\n",
    "test_MNIST_set = CustomTensorDataset(tensors=(test_MNIST_images, test_MNIST_labels), transform=s1c1_PIL)\n",
    "\n",
    "train_MNIST_loader = DataLoader(train_MNIST_set, batch_size=len(train_MNIST_set))\n",
    "test_MNIST_loader = DataLoader(test_MNIST_set, batch_size=len(test_MNIST_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined set of digits + capital letters\n",
    "\n",
    "48000 train + 8000 test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_combi_labels = torch.cat((train_MNIST_labels, train_letter_labels), 0)\n",
    "train_combi_images = torch.cat((train_MNIST_images, train_letters), 0)\n",
    "\n",
    "test_combi_labels = torch.cat((test_MNIST_labels, test_letter_labels), 0)\n",
    "test_combi_images = torch.cat((test_MNIST_images, test_letters), 0)\n",
    "\n",
    "# Element permutation\n",
    "\n",
    "train_order_c = torch.randperm(train_combi_labels.shape[0])\n",
    "test_order_c = torch.randperm(test_combi_labels.shape[0])\n",
    "\n",
    "train_combi_labels = train_combi_labels[train_order_c].view(train_combi_labels.size())\n",
    "train_combi_images = train_combi_images[train_order_c].view(train_combi_images.size())\n",
    "\n",
    "test_combi_labels = test_combi_labels[test_order_c].view(test_combi_labels.size())\n",
    "test_combi_images = test_combi_images[test_order_c].view(test_combi_images.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_combi_set = CustomTensorDataset(tensors=(train_combi_images, \\\n",
    "                                                train_combi_labels), transform=s1c1_PIL)\n",
    "test_combi_set = CustomTensorDataset(tensors=(test_combi_images, \\\n",
    "                                                test_combi_labels), transform=s1c1_PIL)\n",
    "\n",
    "train_combi_loader = DataLoader(train_combi_set, batch_size=len(train_combi_set))\n",
    "test_combi_loader = DataLoader(test_combi_set, batch_size=len(test_combi_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mozafari = MozafariMNIST2018()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n"
     ]
    }
   ],
   "source": [
    "use_cuda = True\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "    device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MozafariMNIST2018(\n",
       "  (conv1): Convolution()\n",
       "  (conv2): Convolution()\n",
       "  (conv3): Convolution()\n",
       "  (stdp1): STDP(\n",
       "    (conv_layer): Convolution()\n",
       "  )\n",
       "  (stdp2): STDP(\n",
       "    (conv_layer): Convolution()\n",
       "  )\n",
       "  (stdp3): STDP(\n",
       "    (conv_layer): Convolution()\n",
       "  )\n",
       "  (anti_stdp3): STDP(\n",
       "    (conv_layer): Convolution()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if use_cuda:\n",
    "    mozafari.cuda()   \n",
    "\n",
    "mozafari.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous learning \n",
    "Training on set of digits + capital letters after training on digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving parameters before training on digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_from_scratch = {'stdp1': [mozafari.stdp1.learning_rate[0][0].item(), \n",
    "                                        mozafari.stdp1.learning_rate[0][1].item()],\n",
    "                              'stdp2': [mozafari.stdp2.learning_rate[0][0].item(), \n",
    "                                        mozafari.stdp2.learning_rate[0][1].item()],\n",
    "                              'stdp3': [mozafari.stdp3.learning_rate[0][0].item(), \n",
    "                                        mozafari.stdp3.learning_rate[0][1].item()],\n",
    "                              'anti_stdp3': [mozafari.anti_stdp3.learning_rate[0][0].item(), \n",
    "                                             mozafari.anti_stdp3.learning_rate[0][1].item()]\n",
    "                             }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation of SNN trained on 24,000 images of digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file \"saved_24000_digits.net\" is the result of the file \"Initial_learning_of_SNN_on_digits.ipynb\"\n",
    "mozafari.load_state_dict(torch.load(\"saved_24000_digits.net\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the first layer\n",
      "Epoch 0\n",
      "0 images\n",
      "10000 images\n",
      "20000 images\n",
      "30000 images\n",
      "40000 images\n",
      "Iteration 0\n",
      "Done!\n",
      "Epoch 1\n",
      "50000 images\n",
      "60000 images\n",
      "70000 images\n",
      "80000 images\n",
      "90000 images\n",
      "Iteration 0\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the first layer\")\n",
    "\n",
    "for epoch in range(2):\n",
    "    print(\"Epoch\", epoch)\n",
    "    iter = 0\n",
    "    for data, targets in train_combi_loader:\n",
    "        print(\"Iteration\", iter)\n",
    "        train_unsupervise(mozafari, data, 1)\n",
    "        print(\"Done!\")\n",
    "        iter+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the second layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the second layer\n",
      "Epoch 0\n",
      "100000 images\n",
      "110000 images\n",
      "120000 images\n",
      "130000 images\n",
      "140000 images\n",
      "Iteration 0\n",
      "Done!\n",
      "Epoch 1\n",
      "150000 images\n",
      "160000 images\n",
      "170000 images\n",
      "180000 images\n",
      "190000 images\n",
      "Iteration 0\n",
      "Done!\n",
      "Epoch 2\n",
      "200000 images\n",
      "210000 images\n",
      "220000 images\n",
      "230000 images\n",
      "Iteration 0\n",
      "Done!\n",
      "Epoch 3\n",
      "240000 images\n",
      "250000 images\n",
      "260000 images\n",
      "270000 images\n",
      "280000 images\n",
      "Iteration 0\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the second layer\")\n",
    "\n",
    "for epoch in range(4):\n",
    "    print(\"Epoch\", epoch)\n",
    "    iter = 0\n",
    "    for data,targets in train_combi_loader:\n",
    "        print(\"Iteration\", iter)\n",
    "        train_unsupervise(mozafari, data, 2)\n",
    "        print(\"Done!\")\n",
    "        iter+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the third layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moving learning_rates \n",
    "\n",
    "for i in range(len(mozafari.stdp3.learning_rate)):\n",
    "                    mozafari.stdp3.learning_rate[i][0].fill_(learning_rate_from_scratch['stdp3'][0])\n",
    "                    mozafari.stdp3.learning_rate[i][1].fill_(learning_rate_from_scratch['stdp3'][1])\n",
    "                    mozafari.anti_stdp3.learning_rate[i][0].fill_(learning_rate_from_scratch['anti_stdp3'][0])\n",
    "                    mozafari.anti_stdp3.learning_rate[i][1].fill_(learning_rate_from_scratch['anti_stdp3'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial adaptive learning rates\n",
    "\n",
    "apr = mozafari.stdp3.learning_rate[0][0].item()\n",
    "anr = mozafari.stdp3.learning_rate[0][1].item()\n",
    "app = mozafari.anti_stdp3.learning_rate[0][1].item()\n",
    "anp = mozafari.anti_stdp3.learning_rate[0][0].item()\n",
    "               \n",
    "parametr_set = pd.DataFrame(columns=['epoch', 'train', 'test', 'test_previous',   \n",
    "                                 'apr_adapt', 'anr_adapt', 'app_adapt', 'anp_adapt', \n",
    "                                 'stdp3.learning_rate[0]', 'stdp3.learning_rate[1]',\n",
    "                                 'anti_stdp3.learning_rate[0]', 'anti_stdp3.learning_rate[1]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training will be performed without weight moving.\n",
      "--------------------------------------------------\n",
      "Epoch #:  0\n",
      "340000 images\n",
      "350000 images\n",
      "360000 images\n",
      "370000 images\n",
      "380000 images\n",
      "Current Train: 66.36%\n",
      "Current Test: 51.30%\n",
      "390000 images\n",
      "Current Test Previous: 85.32%\n",
      "Operational time of epoch #0: 3 min 36 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  1\n",
      "400000 images\n",
      "410000 images\n",
      "420000 images\n",
      "430000 images\n",
      "Current Train: 71.35%\n",
      "440000 images\n",
      "Current Test: 52.12%\n",
      "Current Test Previous: 87.35%\n",
      "Operational time of epoch #1: 3 min 52 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  2\n",
      "450000 images\n",
      "460000 images\n",
      "470000 images\n",
      "480000 images\n",
      "490000 images\n",
      "Current Train: 72.48%\n",
      "Current Test: 53.97%\n",
      "500000 images\n",
      "Current Test Previous: 88.80%\n",
      "Operational time of epoch #2: 3 min 49 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  3\n",
      "510000 images\n",
      "520000 images\n",
      "530000 images\n",
      "540000 images\n",
      "550000 images\n",
      "Current Train: 73.57%\n",
      "Current Test: 55.23%\n",
      "Current Test Previous: 89.40%\n",
      "Operational time of epoch #3: 3 min 55 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  4\n",
      "560000 images\n",
      "570000 images\n",
      "580000 images\n",
      "590000 images\n",
      "600000 images\n",
      "Current Train: 74.53%\n",
      "610000 images\n",
      "Current Test: 57.00%\n",
      "Current Test Previous: 89.90%\n",
      "Operational time of epoch #4: 3 min 42 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  5\n",
      "620000 images\n",
      "630000 images\n",
      "640000 images\n",
      "650000 images\n",
      "660000 images\n",
      "Current Train: 75.64%\n",
      "Current Test: 58.13%\n",
      "670000 images\n",
      "Current Test Previous: 89.98%\n",
      "Operational time of epoch #5: 3 min 43 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  6\n",
      "680000 images\n",
      "690000 images\n",
      "700000 images\n",
      "710000 images\n",
      "Current Train: 76.28%\n",
      "720000 images\n",
      "Current Test: 59.35%\n",
      "Current Test Previous: 90.20%\n",
      "Operational time of epoch #6: 3 min 40 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  7\n",
      "730000 images\n",
      "740000 images\n",
      "750000 images\n",
      "760000 images\n",
      "770000 images\n",
      "Current Train: 76.78%\n",
      "Current Test: 60.55%\n",
      "780000 images\n",
      "Current Test Previous: 90.53%\n",
      "Operational time of epoch #7: 3 min 44 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  8\n",
      "790000 images\n",
      "800000 images\n",
      "810000 images\n",
      "820000 images\n",
      "830000 images\n",
      "Current Train: 77.25%\n",
      "Current Test: 60.88%\n",
      "Current Test Previous: 90.65%\n",
      "Operational time of epoch #8: 3 min 44 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  9\n",
      "840000 images\n",
      "850000 images\n",
      "860000 images\n",
      "870000 images\n",
      "880000 images\n",
      "Current Train: 77.67%\n",
      "890000 images\n",
      "Current Test: 61.92%\n",
      "Current Test Previous: 90.55%\n",
      "Operational time of epoch #9: 3 min 39 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  10\n",
      "900000 images\n",
      "910000 images\n",
      "920000 images\n",
      "930000 images\n",
      "940000 images\n",
      "Current Train: 78.19%\n",
      "Current Test: 62.75%\n",
      "950000 images\n",
      "Current Test Previous: 90.70%\n",
      "Operational time of epoch #10: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  11\n",
      "960000 images\n",
      "970000 images\n",
      "980000 images\n",
      "990000 images\n",
      "Current Train: 78.59%\n",
      "1000000 images\n",
      "Current Test: 63.30%\n",
      "Current Test Previous: 90.60%\n",
      "Operational time of epoch #11: 3 min 39 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  12\n",
      "1010000 images\n",
      "1020000 images\n",
      "1030000 images\n",
      "1040000 images\n",
      "1050000 images\n",
      "Current Train: 78.98%\n",
      "Current Test: 63.82%\n",
      "1060000 images\n",
      "Current Test Previous: 90.72%\n",
      "Operational time of epoch #12: 3 min 39 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  13\n",
      "1070000 images\n",
      "1080000 images\n",
      "1090000 images\n",
      "1100000 images\n",
      "1110000 images\n",
      "Current Train: 79.29%\n",
      "Current Test: 64.42%\n",
      "Current Test Previous: 90.55%\n",
      "Operational time of epoch #13: 3 min 50 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  14\n",
      "1120000 images\n",
      "1130000 images\n",
      "1140000 images\n",
      "1150000 images\n",
      "1160000 images\n",
      "Current Train: 79.68%\n",
      "1170000 images\n",
      "Current Test: 64.90%\n",
      "Current Test Previous: 90.67%\n",
      "Operational time of epoch #14: 3 min 42 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  15\n",
      "1180000 images\n",
      "1190000 images\n",
      "1200000 images\n",
      "1210000 images\n",
      "1220000 images\n",
      "Current Train: 79.98%\n",
      "Current Test: 65.85%\n",
      "1230000 images\n",
      "Current Test Previous: 90.88%\n",
      "Operational time of epoch #15: 3 min 41 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  16\n",
      "1240000 images\n",
      "1250000 images\n",
      "1260000 images\n",
      "1270000 images\n",
      "Current Train: 80.36%\n",
      "1280000 images\n",
      "Current Test: 66.45%\n",
      "Current Test Previous: 90.90%\n",
      "Operational time of epoch #16: 3 min 45 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  17\n",
      "1290000 images\n",
      "1300000 images\n",
      "1310000 images\n",
      "1320000 images\n",
      "1330000 images\n",
      "Current Train: 80.64%\n",
      "Current Test: 66.77%\n",
      "1340000 images\n",
      "Current Test Previous: 90.90%\n",
      "Operational time of epoch #17: 3 min 40 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  18\n",
      "1350000 images\n",
      "1360000 images\n",
      "1370000 images\n",
      "1380000 images\n",
      "1390000 images\n",
      "Current Train: 81.12%\n",
      "Current Test: 67.45%\n",
      "Current Test Previous: 91.07%\n",
      "Operational time of epoch #18: 3 min 48 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  19\n",
      "1400000 images\n",
      "1410000 images\n",
      "1420000 images\n",
      "1430000 images\n",
      "1440000 images\n",
      "Current Train: 81.43%\n",
      "1450000 images\n",
      "Current Test: 67.80%\n",
      "Current Test Previous: 91.17%\n",
      "Operational time of epoch #19: 3 min 53 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  20\n",
      "1460000 images\n",
      "1470000 images\n",
      "1480000 images\n",
      "1490000 images\n",
      "1500000 images\n",
      "Current Train: 81.76%\n",
      "Current Test: 68.15%\n",
      "1510000 images\n",
      "Current Test Previous: 91.15%\n",
      "Operational time of epoch #20: 3 min 40 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  21\n",
      "1520000 images\n",
      "1530000 images\n",
      "1540000 images\n",
      "1550000 images\n",
      "Current Train: 82.10%\n",
      "1560000 images\n",
      "Current Test: 68.75%\n",
      "Current Test Previous: 91.10%\n",
      "Operational time of epoch #21: 3 min 37 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  22\n",
      "1570000 images\n",
      "1580000 images\n",
      "1590000 images\n",
      "1600000 images\n",
      "1610000 images\n",
      "Current Train: 82.35%\n",
      "Current Test: 69.10%\n",
      "1620000 images\n",
      "Current Test Previous: 91.12%\n",
      "Operational time of epoch #22: 3 min 37 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  23\n",
      "1630000 images\n",
      "1640000 images\n",
      "1650000 images\n",
      "1660000 images\n",
      "1670000 images\n",
      "Current Train: 82.66%\n",
      "Current Test: 69.60%\n",
      "Current Test Previous: 91.07%\n",
      "Operational time of epoch #23: 3 min 37 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  24\n",
      "1680000 images\n",
      "1690000 images\n",
      "1700000 images\n",
      "1710000 images\n",
      "1720000 images\n",
      "Current Train: 82.87%\n",
      "1730000 images\n",
      "Current Test: 70.03%\n",
      "Current Test Previous: 91.00%\n",
      "Operational time of epoch #24: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  25\n",
      "1740000 images\n",
      "1750000 images\n",
      "1760000 images\n",
      "1770000 images\n",
      "1780000 images\n",
      "Current Train: 83.05%\n",
      "Current Test: 70.17%\n",
      "1790000 images\n",
      "Current Test Previous: 91.25%\n",
      "Operational time of epoch #25: 3 min 40 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  26\n",
      "1800000 images\n",
      "1810000 images\n",
      "1820000 images\n",
      "1830000 images\n",
      "Current Train: 83.14%\n",
      "1840000 images\n",
      "Current Test: 70.33%\n",
      "Current Test Previous: 90.85%\n",
      "Operational time of epoch #26: 3 min 39 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  27\n",
      "1850000 images\n",
      "1860000 images\n",
      "1870000 images\n",
      "1880000 images\n",
      "1890000 images\n",
      "Current Train: 83.26%\n",
      "Current Test: 70.73%\n",
      "1900000 images\n",
      "Current Test Previous: 90.80%\n",
      "Operational time of epoch #27: 3 min 41 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  28\n",
      "1910000 images\n",
      "1920000 images\n",
      "1930000 images\n",
      "1940000 images\n",
      "1950000 images\n",
      "Current Train: 83.37%\n",
      "Current Test: 71.10%\n",
      "Current Test Previous: 91.03%\n",
      "Operational time of epoch #28: 3 min 41 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  29\n",
      "1960000 images\n",
      "1970000 images\n",
      "1980000 images\n",
      "1990000 images\n",
      "2000000 images\n",
      "Current Train: 83.54%\n",
      "2010000 images\n",
      "Current Test: 71.23%\n",
      "Current Test Previous: 91.07%\n",
      "Operational time of epoch #29: 3 min 41 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  30\n",
      "2020000 images\n",
      "2030000 images\n",
      "2040000 images\n",
      "2050000 images\n",
      "2060000 images\n",
      "Current Train: 83.65%\n",
      "Current Test: 71.33%\n",
      "2070000 images\n",
      "Current Test Previous: 91.07%\n",
      "Operational time of epoch #30: 3 min 39 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2080000 images\n",
      "2090000 images\n",
      "2100000 images\n",
      "2110000 images\n",
      "Current Train: 83.85%\n",
      "2120000 images\n",
      "Current Test: 71.80%\n",
      "Current Test Previous: 91.05%\n",
      "Operational time of epoch #31: 3 min 36 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  32\n",
      "2130000 images\n",
      "2140000 images\n",
      "2150000 images\n",
      "2160000 images\n",
      "2170000 images\n",
      "Current Train: 84.02%\n",
      "Current Test: 71.92%\n",
      "2180000 images\n",
      "Current Test Previous: 91.00%\n",
      "Operational time of epoch #32: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  33\n",
      "2190000 images\n",
      "2200000 images\n",
      "2210000 images\n",
      "2220000 images\n",
      "2230000 images\n",
      "Current Train: 84.12%\n",
      "Current Test: 72.00%\n",
      "Current Test Previous: 90.90%\n",
      "Operational time of epoch #33: 3 min 42 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  34\n",
      "2240000 images\n",
      "2250000 images\n",
      "2260000 images\n",
      "2270000 images\n",
      "2280000 images\n",
      "Current Train: 84.24%\n",
      "2290000 images\n",
      "Current Test: 72.28%\n",
      "Current Test Previous: 90.97%\n",
      "Operational time of epoch #34: 3 min 45 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  35\n",
      "2300000 images\n",
      "2310000 images\n",
      "2320000 images\n",
      "2330000 images\n",
      "2340000 images\n",
      "Current Train: 84.34%\n",
      "Current Test: 72.25%\n",
      "2350000 images\n",
      "Current Test Previous: 90.90%\n",
      "Operational time of epoch #35: 3 min 39 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  36\n",
      "2360000 images\n",
      "2370000 images\n",
      "2380000 images\n",
      "2390000 images\n",
      "Current Train: 84.47%\n",
      "2400000 images\n",
      "Current Test: 72.78%\n",
      "Current Test Previous: 90.95%\n",
      "Operational time of epoch #36: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  37\n",
      "2410000 images\n",
      "2420000 images\n",
      "2430000 images\n",
      "2440000 images\n",
      "2450000 images\n",
      "Current Train: 84.59%\n",
      "Current Test: 72.92%\n",
      "2460000 images\n",
      "Current Test Previous: 91.00%\n",
      "Operational time of epoch #37: 3 min 39 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  38\n",
      "2470000 images\n",
      "2480000 images\n",
      "2490000 images\n",
      "2500000 images\n",
      "2510000 images\n",
      "Current Train: 84.73%\n",
      "Current Test: 73.25%\n",
      "Current Test Previous: 91.12%\n",
      "Operational time of epoch #38: 3 min 39 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  39\n",
      "2520000 images\n",
      "2530000 images\n",
      "2540000 images\n",
      "2550000 images\n",
      "2560000 images\n",
      "Current Train: 84.89%\n",
      "2570000 images\n",
      "Current Test: 73.25%\n",
      "Current Test Previous: 91.03%\n",
      "Operational time of epoch #39: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  40\n",
      "2580000 images\n",
      "2590000 images\n",
      "2600000 images\n",
      "2610000 images\n",
      "2620000 images\n",
      "Current Train: 84.97%\n",
      "Current Test: 73.50%\n",
      "2630000 images\n",
      "Current Test Previous: 91.12%\n",
      "Operational time of epoch #40: 3 min 39 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  41\n",
      "2640000 images\n",
      "2650000 images\n",
      "2660000 images\n",
      "2670000 images\n",
      "Current Train: 85.15%\n",
      "2680000 images\n",
      "Current Test: 73.83%\n",
      "Current Test Previous: 91.07%\n",
      "Operational time of epoch #41: 3 min 39 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  42\n",
      "2690000 images\n",
      "2700000 images\n",
      "2710000 images\n",
      "2720000 images\n",
      "2730000 images\n",
      "Current Train: 85.29%\n",
      "Current Test: 74.05%\n",
      "2740000 images\n",
      "Current Test Previous: 91.27%\n",
      "Operational time of epoch #42: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  43\n",
      "2750000 images\n",
      "2760000 images\n",
      "2770000 images\n",
      "2780000 images\n",
      "2790000 images\n",
      "Current Train: 85.41%\n",
      "Current Test: 74.38%\n",
      "Current Test Previous: 91.10%\n",
      "Operational time of epoch #43: 3 min 39 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  44\n",
      "2800000 images\n",
      "2810000 images\n",
      "2820000 images\n",
      "2830000 images\n",
      "2840000 images\n",
      "Current Train: 85.47%\n",
      "2850000 images\n",
      "Current Test: 74.70%\n",
      "Current Test Previous: 91.12%\n",
      "Operational time of epoch #44: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  45\n",
      "2860000 images\n",
      "2870000 images\n",
      "2880000 images\n",
      "2890000 images\n",
      "2900000 images\n",
      "Current Train: 85.69%\n",
      "Current Test: 74.80%\n",
      "2910000 images\n",
      "Current Test Previous: 91.17%\n",
      "Operational time of epoch #45: 3 min 37 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  46\n",
      "2920000 images\n",
      "2930000 images\n",
      "2940000 images\n",
      "2950000 images\n",
      "Current Train: 85.75%\n",
      "2960000 images\n",
      "Current Test: 74.88%\n",
      "Current Test Previous: 91.10%\n",
      "Operational time of epoch #46: 3 min 39 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  47\n",
      "2970000 images\n",
      "2980000 images\n",
      "2990000 images\n",
      "3000000 images\n",
      "3010000 images\n",
      "Current Train: 85.85%\n",
      "Current Test: 75.00%\n",
      "3020000 images\n",
      "Current Test Previous: 91.05%\n",
      "Operational time of epoch #47: 3 min 37 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  48\n",
      "3030000 images\n",
      "3040000 images\n",
      "3050000 images\n",
      "3060000 images\n",
      "3070000 images\n",
      "Current Train: 86.03%\n",
      "Current Test: 74.92%\n",
      "Current Test Previous: 91.17%\n",
      "Operational time of epoch #48: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  49\n",
      "3080000 images\n",
      "3090000 images\n",
      "3100000 images\n",
      "3110000 images\n",
      "3120000 images\n",
      "Current Train: 86.13%\n",
      "3130000 images\n",
      "Current Test: 75.42%\n",
      "Current Test Previous: 91.15%\n",
      "Operational time of epoch #49: 3 min 39 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  50\n",
      "3140000 images\n",
      "3150000 images\n",
      "3160000 images\n",
      "3170000 images\n",
      "3180000 images\n",
      "Current Train: 86.16%\n",
      "Current Test: 75.62%\n",
      "3190000 images\n",
      "Current Test Previous: 91.17%\n",
      "Operational time of epoch #50: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  51\n",
      "3200000 images\n",
      "3210000 images\n",
      "3220000 images\n",
      "3230000 images\n",
      "Current Train: 86.25%\n",
      "3240000 images\n",
      "Current Test: 75.70%\n",
      "Current Test Previous: 91.12%\n",
      "Operational time of epoch #51: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  52\n",
      "3250000 images\n",
      "3260000 images\n",
      "3270000 images\n",
      "3280000 images\n",
      "3290000 images\n",
      "Current Train: 86.34%\n",
      "Current Test: 75.95%\n",
      "3300000 images\n",
      "Current Test Previous: 91.17%\n",
      "Operational time of epoch #52: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  53\n",
      "3310000 images\n",
      "3320000 images\n",
      "3330000 images\n",
      "3340000 images\n",
      "3350000 images\n",
      "Current Train: 86.48%\n",
      "Current Test: 76.22%\n",
      "Current Test Previous: 91.27%\n",
      "Operational time of epoch #53: 3 min 39 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  54\n",
      "3360000 images\n",
      "3370000 images\n",
      "3380000 images\n",
      "3390000 images\n",
      "3400000 images\n",
      "Current Train: 86.52%\n",
      "3410000 images\n",
      "Current Test: 76.53%\n",
      "Current Test Previous: 91.22%\n",
      "Operational time of epoch #54: 3 min 39 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  55\n",
      "3420000 images\n",
      "3430000 images\n",
      "3440000 images\n",
      "3450000 images\n",
      "3460000 images\n",
      "Current Train: 86.61%\n",
      "Current Test: 76.85%\n",
      "3470000 images\n",
      "Current Test Previous: 91.22%\n",
      "Operational time of epoch #55: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  56\n",
      "3480000 images\n",
      "3490000 images\n",
      "3500000 images\n",
      "3510000 images\n",
      "Current Train: 86.72%\n",
      "3520000 images\n",
      "Current Test: 77.15%\n",
      "Current Test Previous: 91.27%\n",
      "Operational time of epoch #56: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  57\n",
      "3530000 images\n",
      "3540000 images\n",
      "3550000 images\n",
      "3560000 images\n",
      "3570000 images\n",
      "Current Train: 86.90%\n",
      "Current Test: 77.75%\n",
      "3580000 images\n",
      "Current Test Previous: 91.50%\n",
      "Operational time of epoch #57: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  58\n",
      "3590000 images\n",
      "3600000 images\n",
      "3610000 images\n",
      "3620000 images\n",
      "3630000 images\n",
      "Current Train: 86.93%\n",
      "Current Test: 77.70%\n",
      "Current Test Previous: 91.40%\n",
      "Operational time of epoch #58: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  59\n",
      "3640000 images\n",
      "3650000 images\n",
      "3660000 images\n",
      "3670000 images\n",
      "3680000 images\n",
      "Current Train: 86.99%\n",
      "3690000 images\n",
      "Current Test: 77.88%\n",
      "Current Test Previous: 91.60%\n",
      "Operational time of epoch #59: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  60\n",
      "3700000 images\n",
      "3710000 images\n",
      "3720000 images\n",
      "3730000 images\n",
      "3740000 images\n",
      "Current Train: 87.15%\n",
      "Current Test: 78.00%\n",
      "3750000 images\n",
      "Current Test Previous: 91.60%\n",
      "Operational time of epoch #60: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  61\n",
      "3760000 images\n",
      "3770000 images\n",
      "3780000 images\n",
      "3790000 images\n",
      "Current Train: 87.14%\n",
      "3800000 images\n",
      "Current Test: 78.08%\n",
      "Current Test Previous: 91.65%\n",
      "Operational time of epoch #61: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3810000 images\n",
      "3820000 images\n",
      "3830000 images\n",
      "3840000 images\n",
      "3850000 images\n",
      "Current Train: 87.24%\n",
      "Current Test: 78.10%\n",
      "3860000 images\n",
      "Current Test Previous: 91.53%\n",
      "Operational time of epoch #62: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  63\n",
      "3870000 images\n",
      "3880000 images\n",
      "3890000 images\n",
      "3900000 images\n",
      "3910000 images\n",
      "Current Train: 87.31%\n",
      "Current Test: 78.17%\n",
      "Current Test Previous: 91.57%\n",
      "Operational time of epoch #63: 3 min 37 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  64\n",
      "3920000 images\n",
      "3930000 images\n",
      "3940000 images\n",
      "3950000 images\n",
      "3960000 images\n",
      "Current Train: 87.42%\n",
      "3970000 images\n",
      "Current Test: 78.27%\n",
      "Current Test Previous: 91.57%\n",
      "Operational time of epoch #64: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  65\n",
      "3980000 images\n",
      "3990000 images\n",
      "4000000 images\n",
      "4010000 images\n",
      "4020000 images\n",
      "Current Train: 87.46%\n",
      "Current Test: 78.42%\n",
      "4030000 images\n",
      "Current Test Previous: 91.65%\n",
      "Operational time of epoch #65: 3 min 37 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  66\n",
      "4040000 images\n",
      "4050000 images\n",
      "4060000 images\n",
      "4070000 images\n",
      "Current Train: 87.58%\n",
      "4080000 images\n",
      "Current Test: 78.40%\n",
      "Current Test Previous: 91.53%\n",
      "Operational time of epoch #66: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  67\n",
      "4090000 images\n",
      "4100000 images\n",
      "4110000 images\n",
      "4120000 images\n",
      "4130000 images\n",
      "Current Train: 87.62%\n",
      "Current Test: 78.50%\n",
      "4140000 images\n",
      "Current Test Previous: 91.47%\n",
      "Operational time of epoch #67: 3 min 37 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  68\n",
      "4150000 images\n",
      "4160000 images\n",
      "4170000 images\n",
      "4180000 images\n",
      "4190000 images\n",
      "Current Train: 87.69%\n",
      "Current Test: 78.62%\n",
      "Current Test Previous: 91.60%\n",
      "Operational time of epoch #68: 3 min 37 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  69\n",
      "4200000 images\n",
      "4210000 images\n",
      "4220000 images\n",
      "4230000 images\n",
      "4240000 images\n",
      "Current Train: 87.82%\n",
      "4250000 images\n",
      "Current Test: 78.80%\n",
      "Current Test Previous: 91.62%\n",
      "Operational time of epoch #69: 3 min 37 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  70\n",
      "4260000 images\n",
      "4270000 images\n",
      "4280000 images\n",
      "4290000 images\n",
      "4300000 images\n",
      "Current Train: 87.90%\n",
      "Current Test: 78.88%\n",
      "4310000 images\n",
      "Current Test Previous: 91.57%\n",
      "Operational time of epoch #70: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  71\n",
      "4320000 images\n",
      "4330000 images\n",
      "4340000 images\n",
      "4350000 images\n",
      "Current Train: 88.02%\n",
      "4360000 images\n",
      "Current Test: 79.10%\n",
      "Current Test Previous: 91.60%\n",
      "Operational time of epoch #71: 3 min 39 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  72\n",
      "4370000 images\n",
      "4380000 images\n",
      "4390000 images\n",
      "4400000 images\n",
      "4410000 images\n",
      "Current Train: 88.04%\n",
      "Current Test: 79.00%\n",
      "4420000 images\n",
      "Current Test Previous: 91.53%\n",
      "Operational time of epoch #72: 3 min 37 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  73\n",
      "4430000 images\n",
      "4440000 images\n",
      "4450000 images\n",
      "4460000 images\n",
      "4470000 images\n",
      "Current Train: 88.15%\n",
      "Current Test: 79.25%\n",
      "Current Test Previous: 91.53%\n",
      "Operational time of epoch #73: 3 min 42 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  74\n",
      "4480000 images\n",
      "4490000 images\n",
      "4500000 images\n",
      "4510000 images\n",
      "4520000 images\n",
      "Current Train: 88.13%\n",
      "4530000 images\n",
      "Current Test: 79.05%\n",
      "Current Test Previous: 91.55%\n",
      "Operational time of epoch #74: 3 min 41 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  75\n",
      "4540000 images\n",
      "4550000 images\n",
      "4560000 images\n",
      "4570000 images\n",
      "4580000 images\n",
      "Current Train: 88.24%\n",
      "Current Test: 79.47%\n",
      "4590000 images\n",
      "Current Test Previous: 91.55%\n",
      "Operational time of epoch #75: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  76\n",
      "4600000 images\n",
      "4610000 images\n",
      "4620000 images\n",
      "4630000 images\n",
      "Current Train: 88.30%\n",
      "4640000 images\n",
      "Current Test: 79.75%\n",
      "Current Test Previous: 91.72%\n",
      "Operational time of epoch #76: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  77\n",
      "4650000 images\n",
      "4660000 images\n",
      "4670000 images\n",
      "4680000 images\n",
      "4690000 images\n",
      "Current Train: 88.37%\n",
      "Current Test: 79.88%\n",
      "4700000 images\n",
      "Current Test Previous: 91.70%\n",
      "Operational time of epoch #77: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  78\n",
      "4710000 images\n",
      "4720000 images\n",
      "4730000 images\n",
      "4740000 images\n",
      "4750000 images\n",
      "Current Train: 88.51%\n",
      "Current Test: 80.08%\n",
      "Current Test Previous: 91.75%\n",
      "Operational time of epoch #78: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  79\n",
      "4760000 images\n",
      "4770000 images\n",
      "4780000 images\n",
      "4790000 images\n",
      "4800000 images\n",
      "Current Train: 88.53%\n",
      "4810000 images\n",
      "Current Test: 80.08%\n",
      "Current Test Previous: 91.60%\n",
      "Operational time of epoch #79: 3 min 41 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  80\n",
      "4820000 images\n",
      "4830000 images\n",
      "4840000 images\n",
      "4850000 images\n",
      "4860000 images\n",
      "Current Train: 88.67%\n",
      "Current Test: 80.20%\n",
      "4870000 images\n",
      "Current Test Previous: 91.75%\n",
      "Operational time of epoch #80: 3 min 41 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  81\n",
      "4880000 images\n",
      "4890000 images\n",
      "4900000 images\n",
      "4910000 images\n",
      "Current Train: 88.69%\n",
      "4920000 images\n",
      "Current Test: 80.20%\n",
      "Current Test Previous: 91.70%\n",
      "Operational time of epoch #81: 3 min 41 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  82\n",
      "4930000 images\n",
      "4940000 images\n",
      "4950000 images\n",
      "4960000 images\n",
      "4970000 images\n",
      "Current Train: 88.79%\n",
      "Current Test: 80.27%\n",
      "4980000 images\n",
      "Current Test Previous: 91.77%\n",
      "Operational time of epoch #82: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  83\n",
      "4990000 images\n",
      "5000000 images\n",
      "5010000 images\n",
      "5020000 images\n",
      "5030000 images\n",
      "Current Train: 88.87%\n",
      "Current Test: 80.25%\n",
      "Current Test Previous: 91.72%\n",
      "Operational time of epoch #83: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  84\n",
      "5040000 images\n",
      "5050000 images\n",
      "5060000 images\n",
      "5070000 images\n",
      "5080000 images\n",
      "Current Train: 88.90%\n",
      "5090000 images\n",
      "Current Test: 80.27%\n",
      "Current Test Previous: 91.83%\n",
      "Operational time of epoch #84: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  85\n",
      "5100000 images\n",
      "5110000 images\n",
      "5120000 images\n",
      "5130000 images\n",
      "5140000 images\n",
      "Current Train: 89.03%\n",
      "Current Test: 80.33%\n",
      "5150000 images\n",
      "Current Test Previous: 91.97%\n",
      "Operational time of epoch #85: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  86\n",
      "5160000 images\n",
      "5170000 images\n",
      "5180000 images\n",
      "5190000 images\n",
      "Current Train: 89.07%\n",
      "5200000 images\n",
      "Current Test: 80.33%\n",
      "Current Test Previous: 91.88%\n",
      "Operational time of epoch #86: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  87\n",
      "5210000 images\n",
      "5220000 images\n",
      "5230000 images\n",
      "5240000 images\n",
      "5250000 images\n",
      "Current Train: 89.07%\n",
      "Current Test: 80.50%\n",
      "5260000 images\n",
      "Current Test Previous: 91.92%\n",
      "Operational time of epoch #87: 3 min 37 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  88\n",
      "5270000 images\n",
      "5280000 images\n",
      "5290000 images\n",
      "5300000 images\n",
      "5310000 images\n",
      "Current Train: 89.17%\n",
      "Current Test: 80.42%\n",
      "Current Test Previous: 92.05%\n",
      "Operational time of epoch #88: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  89\n",
      "5320000 images\n",
      "5330000 images\n",
      "5340000 images\n",
      "5350000 images\n",
      "5360000 images\n",
      "Current Train: 89.19%\n",
      "5370000 images\n",
      "Current Test: 80.42%\n",
      "Current Test Previous: 91.77%\n",
      "Operational time of epoch #89: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  90\n",
      "5380000 images\n",
      "5390000 images\n",
      "5400000 images\n",
      "5410000 images\n",
      "5420000 images\n",
      "Current Train: 89.24%\n",
      "Current Test: 80.42%\n",
      "5430000 images\n",
      "Current Test Previous: 92.00%\n",
      "Operational time of epoch #90: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  91\n",
      "5440000 images\n",
      "5450000 images\n",
      "5460000 images\n",
      "5470000 images\n",
      "Current Train: 89.29%\n",
      "5480000 images\n",
      "Current Test: 80.60%\n",
      "Current Test Previous: 92.03%\n",
      "Operational time of epoch #91: 3 min 42 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  92\n",
      "5490000 images\n",
      "5500000 images\n",
      "5510000 images\n",
      "5520000 images\n",
      "5530000 images\n",
      "Current Train: 89.35%\n",
      "Current Test: 80.62%\n",
      "5540000 images\n",
      "Current Test Previous: 92.05%\n",
      "Operational time of epoch #92: 3 min 39 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5550000 images\n",
      "5560000 images\n",
      "5570000 images\n",
      "5580000 images\n",
      "5590000 images\n",
      "Current Train: 89.44%\n",
      "Current Test: 80.60%\n",
      "Current Test Previous: 91.90%\n",
      "Operational time of epoch #93: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  94\n",
      "5600000 images\n",
      "5610000 images\n",
      "5620000 images\n",
      "5630000 images\n",
      "5640000 images\n",
      "Current Train: 89.41%\n",
      "5650000 images\n",
      "Current Test: 80.62%\n",
      "Current Test Previous: 92.15%\n",
      "Operational time of epoch #94: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  95\n",
      "5660000 images\n",
      "5670000 images\n",
      "5680000 images\n",
      "5690000 images\n",
      "5700000 images\n",
      "Current Train: 89.42%\n",
      "Current Test: 80.53%\n",
      "5710000 images\n",
      "Current Test Previous: 92.07%\n",
      "Operational time of epoch #95: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  96\n",
      "5720000 images\n",
      "5730000 images\n",
      "5740000 images\n",
      "5750000 images\n",
      "Current Train: 89.51%\n",
      "5760000 images\n",
      "Current Test: 80.55%\n",
      "Current Test Previous: 92.10%\n",
      "Operational time of epoch #96: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  97\n",
      "5770000 images\n",
      "5780000 images\n",
      "5790000 images\n",
      "5800000 images\n",
      "5810000 images\n",
      "Current Train: 89.52%\n",
      "Current Test: 80.58%\n",
      "5820000 images\n",
      "Current Test Previous: 92.27%\n",
      "Operational time of epoch #97: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  98\n",
      "5830000 images\n",
      "5840000 images\n",
      "5850000 images\n",
      "5860000 images\n",
      "5870000 images\n",
      "Current Train: 89.53%\n",
      "Current Test: 80.70%\n",
      "Current Test Previous: 92.20%\n",
      "Operational time of epoch #98: 3 min 38 sec\n",
      "--------------------------------------------------\n",
      "Epoch #:  99\n",
      "5880000 images\n",
      "5890000 images\n",
      "5900000 images\n",
      "5910000 images\n",
      "5920000 images\n",
      "Current Train: 89.49%\n",
      "5930000 images\n",
      "Current Test: 80.70%\n",
      "Current Test Previous: 92.00%\n",
      "Operational time of epoch #99: 3 min 38 sec\n",
      "==================== SUMMARY ====================\n",
      "        Best Train: 89.53% on 98 epoch\n",
      "         Best Test: 80.70% on 99 epoch\n",
      "Best Test Previous: 92.27% on 97 epoch\n"
     ]
    }
   ],
   "source": [
    "# train the 3-rd layer\n",
    "\n",
    "first_test = third_layer(file_name_net=\"saved_letter+digit_after_digit_total_0.net\",\n",
    "                        file_name_csv='parameter_set_letter+digit_after_digit_0.csv',\n",
    "                        adaptive_int=0.5, previous_epochs=0, epochs=100, \n",
    "                        train_loader=train_combi_loader, \n",
    "                        test_loader=test_letter_loader, \n",
    "                        test_previous_loader=test_MNIST_loader,\n",
    "                        model=mozafari, apr=apr, anr=anr, app=app, anp=anp, \n",
    "                        parametr_set=parametr_set, steps=0, percent=0, it_continues=False)\n",
    "\n",
    "parametr_set = first_test[0] \n",
    "counter = first_test[1] \n",
    "previous_epochs = first_test[2]\n",
    "apr = first_test[3] \n",
    "anr = first_test[4] \n",
    "app = first_test[5] \n",
    "anp = first_test[6]\n",
    "conv3_data_train = first_test[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA30AAAFFCAYAAABYPIRQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABg9UlEQVR4nO3dd3iUVdrH8e+hVwHpqAQsawNEBRsWsAHq2l1dQUGqq+taVuyrrorr2staQREFRdeu4L6ogGBBAUXFgqDSpHcCSSDJ/f5x5mEmyUzqlGTy+1zXc82cOfM8c2ZyAnPnPsWZGSIiIiIiIpKeaqS6ASIiIiIiIpI4CvpERERERETSmII+ERERERGRNKagT0REREREJI0p6BMREREREUljCvpERERERETSWK1UNyAeWrRoYR06dEh1M4rYunUrDRs2THUzJM2pn0miqY9JMqifSTKon0kypKqfzZkzZ62ZtYxWV+GgzznXAlhnKdzwr0OHDsyePTtVLx/TtGnT6NmzZ6qbIWlO/UwSTX1MkkH9TJJB/UySIVX9zDm3OFZduYZ3OufqO+eeds5tA1YBWc65sc65JuVtpIiIiIiIiMRfeTN9jwI9gMuA5cABwC1AbeDC+DRNREREREREKqrYoM85d7iZfRGlqjdwrpl9GSpPds4ZcFu8GygiIiIiIiLlV9Lwzg+dc6Odc4UnBK4CegYF51wN4KjQ4yIiIiIiIlJJlBT0HQg0A+Y75/4aCu4AbgbudM794pz7BD/E82zgH4lrqoiIiIiIiJRVsUGfmS0xs3OAP+Hn733tnDvGzCYD+wPPAd8CjwNdzOy1RDdYRERERERESq9UC7mY2YfOuS7A1cB7zrl3gWvNbGRCWyciIiIiIiIVUuotG8ws18zuA/YDHH7I57XOubTY4F1ERERERCQdlRj0OecOc87d5Zx70Dn3JzNbYWb9gNOAfsB3zrkTE95SERERERERKbNigz7n3MXA58AFwLHAy8658QBmNgM4FHgCeNU595pzbo8Et1dERERERKTstm6Fjz6ClSvD5c8+gw0bfDk/H8xS174EKinTdwsw1sz2NrNu+I3XL3DOZQCYWb6ZPQbsC2wCfkhoa0VEREREpHLLzy/feWbwwQcwe3b4sbvugsmTw+X/+z/45Zfw68yYAYsX+/KOHfDmm/Dzz768ciX07Qvvv+/LixfDiSfClCm+/NNP0KMHTJ/uy7NmQa1a8O67vrx0KTz0ECxfXr73U4mUFPS1AiI+dWbh5/MV2LfPzNaY2WCgV3ybJyIiIiKSZhYsgN9+8/fN4Kqr4O23w/XTp8OSJeFyXp4PaIL7P/wAq1f78tatMHasfwxg2TI4+miYNMmXly+Hrl19his4v7ig7Lff4I03wuXHHoOTTgqX77wTDj88XL76ajjwwHB5wADYe+9w+brr4Nxzw+WpU8NBF/igavRof985f/6jj4br77nHnwO+3aecAs8/H34vxx4LL77oyzk5cPbZ4c+ycWNYtQqysnx57739a/ftGy6//z4ceaQvt24NN97oPy/wQeA114Q/6/ff9++9CmYDSwr6Pgaud85d6Jw7FXgKWAt8H+3JZjY72uMiIiIiIjvl5vov4rGCD7OC9evXw1dfwfbt5Xu9jRvhu+/C5fXrYc2a2M9fswYWLQqXp0yBd94Jl7/9tuj11q4Nl996C/73v3B5+HC4++5w+ZhjwmXnfID22We+bAYnnABPPeXL27f77NN99/lyVpYPsl54IVw/cGD49Ro2hNq1/XUBNm/2wUyTJr48YwY0awZffOHL06bBhReGP9sXX/RB2tatvly7NtSrF277brtB587hcvfucOaZ4fKZZ8KVV4bLzZtDmzbh8siRcMst4fI778CHH4bL778PjzwSLm/Z4rN9gc8+gyFD/P1atXxmsH9/X27QAObO9Z9H8Fl89ZUPBAHq1IFevfz7B/+Z9OkDrVr5cocO/rX2CM1YO/ts3xc6dfLlunXhkEPCn21VYmYxD6AN8H9AHpAPzAeOLe6cVByHHnqoVUZTp05NdROkGlA/k0RTH5MK2brVLDvb31+zxuy118xWrvTlVat8ec0a389++83sscf842ZmX39tdvnlZr//7su//GI2ZozZhg2+vGOHWX5+wdfLzw8/tnGj2fz54fKqVWbffhsur1xpNm9e+NzZs81efDFcfukls+HDw+W5c82mTy/3R2FmZnl54fv/939mM2aEyxMmmP3vf+Hyk0+avfdeuDx5sm9D4LvvzBYvDpenTjX78cdw+aOP/GcWyMws+nmVV36+WU6OWW5u9PKGDWZvvBH+Wc+YYdaxo/+Zmpm9+64ZmM2a5ctvvmnWoIF/T2b+5wBmCxf68ujRvhy83+eeM9tjj/D1v/zS7PHHzbKyfHnsWLPzzgu3d+hQs1atwv+eDRpktttu4fpBg8y6dQuXzzzTrHPncPnUU826dw+XTzjBrEePcPmYY8xOPjlc7tbNrE+fcPm888xuvDFcfu+9gj/L4DM0833k44/Nfv45/Pjtt4f7Xl6e2Suv+L4d1C9YEH7vJfn2W7NLLzVbu9aXX3rJrEMHs0WLfHnpUv97Efws423FivB7M/O/x2kmVf9vArMtVlwXq6LAk6Ae0LQ0z03FoaBPqjP1M0k09bFqLDfX7P33zb75xpfz882GDDGbNMmX8/LM3nkn/GVxwwazp582++knX/7iCzPnws+fMcN/9fjgA1/+8ENfnj7d97NJk3z58899/Xvvme26a/j1n3++YCDw3HNmtWuHX/+RR/zrbdzoy/fc45+/bZsv33mnLwdfMv/xD7OaNcNftkeMMKtbN/z+b77ZLPI7xoABZrvvHi5feqlZz57h8m23+ccCTzxhdu+94fIJJ5j17RsuH3KI2WmnhcsHHmh29tnh8j77mPXvHy7vvrvZJZeEyy1bFny9Jk3MrrwyXK5b1+y66/z9/Hz/Xm++2ZdzcvwX/f/8x5e3bPHlZ57x5bVrzVq39sGWmdmyZf78oP633/xnOWaML//0ky+/9JIvz5njy6+/7svz55v9+c/hIHvBArN//csHAGb+Z/z3v4fL33/vf35BYLJokdlbb/nA1cz3nQEDzLZv9+VbbzWrUSNcfvhhs8MOC/+sZ840e++98L9nH39sNm5c+LMaN87//AJTp/rANLBsWfiPD2ZmX33l+3fgtdf870Lg99/NNm2yKiFefwiQnaps0FfZDwV9Up1Vun6m/zzSTrn6WHZ2+Iu3mf+CGHwZk7LZuNFsyZJw+cMPfYYosGCBPwJbtpht3hwub97sHwusWhXOjpj5ACvIvpiZXXON2ahR/n5enlnDhmZ/+5svZ2b6wOPhh315/Xr/VeKhh3z59999OQgk1q83++c/w0FgZqbPMgTt2bLFlzMzfT/LyjJbvTr2X/6zsnzAF9R/+aXZDTeEg7rPPvOBXBAYzJtnNn68D3DMzH74wX85D7Jt8+b5cpDRWL3af9ax/h1btKjgF/2nny6YvbnuOrOLLgqXzz23YPbnySfDn62Z/7lFZurWrCn4e5OV5TOlgW+/LZi5mzSpYLbos8/Mfv3V38/P9+UgQM7N9QFokC3ascPs4ovDgcq2bb4cBOiZmWbDhvlsoZnvRzfd5D9zMx/gjxwZDsjXrvXlIKjLyvKZ0+BnkWh5eQX7dQyV7v9MSUsK+hT0iRQ1b17BL2z33OOHuQROPdUPdwpceKHZCy/sLC4955zw8J/8fP/c2bN9eft2PwQkGO6zbZsf/hL8J71tm/9L9Pff+3J2ttmUKeG/tObm+v/YI4cjRcrP91/mg6Fbr79u1qpV+D/eyZPNbrml4BfORMnN9UNSgr+sbt/uv+CtX+/LOTm+HAwL277d/+U2+LKYl+ffR7oErStX+i+IgalTw39xN/OfS+SXSbOC733OnJ1fbqcG5wZfBs38F7+g35j5DMz77/v7eXl+mNaIEb68Y4dZrVrhL8e5uWZ/+YvZtGm+nJnpv5gHvwcbNviMTdBvly/3gUjw5fbnn322ZOZMX/71V7PBg8Pvd8UKn31YvtyXN2707yf48rl9u3/vwftdutT/ngR9YdIks5NO8gGAmf9r/x//GP4y/v77ZgMHhvv9f/9rdvrp4cBh9GizY48Nl197reAQwSlTzB54IFweO9bsiivC5TvvLJgNOu88s/33D5fPOsvs4IPD5d69fUYj0KuXH2oWOOoosxNPDJcPPrhgdqlTp4LZpaOO8p93YPbs8O9RYdu3++F5QQYkP98HRrH+zSiG/s+UZFA/k2SojEFfiZuzi0ghubmQnR0ur18fXtUJ/ETuyPKqVeGlhcGvchU5IfmUU+Cf/wyXH3+84ORv/9eZcPmnn8LXN6PVRx/BN9/48o4dcMUVfjlj8JOyzz8/vPRwVhZcfnl4Faz16+Gyy+CTT3x5xQo4/vjw6//6q5/s/NJLvrxggZ+8HUy4njQJOnb0q1sBZGT495OT48tffOFX5Kpf35cnTw6/dmkF733rVvjb38KrkW3Y4Ffl+s9/fHnNGj/xevx4X161Cg44AF5/3ZeXLfPlYCL+woWw++7hFb6++85PVH/zTV+eO9dfL1hhbN48OPnk8DLSS5b4iebBMs6ZmX7Fs2B1taVL4dVX/eMAM2fCiBHhif6//OJfK1hRbMsWv2hAsGjBb7/5n0Pw/r/4ouDE9rfe8p9H4MEH/c8ucOONfnJ64Kmn/GOBoUP95PvAmWf6ye2Bq66C668Pl+++2/fNwODBBSfi3303jBnj79eo4VdbO/VUX87Lg1Gj4JxzfHnNGv/ZzJ/vy+vXQ79+fjEBgHXr/CIAX34Z/mxGjSr4e7R2bfj3cO1aP/E/2Gdp3jy45BL/MwY/6f/QQ8OLLrz/vp/c//XXvjx9uv89CZb83r7dL3xQs6YvZ2b6n2dgyRL/OxD8rDdu9Ofm5vpyzZp+cYHg/PnzCy43/tZbcOut4fKCBeEFHMC3LVhUAODSS/1qeYHHH/efX+DWW/3nHbjsMv/vQOBvf4O//KXg8yPrn3++4AITn34KDzwQLh96aHjRg8Jq14Zu3aBdO192zv87UENfL0REKpVY0WBVOpTpE8vLK9dflqP64Qezt98Ol4cPLziZ+5xzzA44IFz+4x/NDjooXO7Tp+Bf3Y8/3uy448LlCy4oOOdiypSCw3PKOKG5QD/Lz/dDbIKhXXl5PpMYzIkIhr8EGY3cXJ8VCTJx27b5jFCQIVmzxmckgqFZCxf6LEMwvGnNGj9cKXh+NJETy3v0MDv88HB56FCf1QjccUc4i5mXZ7bffuHsUF6eWZs24QxJTo7PRnz8sS9nZ/u5JkH2aetWvyhCMBRqyxZf/u03X163zg/NCoY+rVjhhyYFk8sXLPBzZ4Ls0Zw5ZkccUXQRgmCo01tv+XLw/Jde8uUffvDlcePM6tf32UUzP/wNwgtWPPSQLwc/u7vv9uXg87v9dl8Oskd33mnWrl04W/X00z5bE5RnzSqYmduwoeAwsvfeKzifZdSoghnlr7/e2fapU6f6zyvIfJn59x1kjM38+yjrpP/gd3b7dt/Hgkxabq7vs8GQvLLKzvbZv6Cfr1zpf6eDbNX8+Wb//nf4/axb539uQeYu0bZv11DXKPR/piSD+pkkQ2XM9KU8YIvHoaAvBXJywoFCfr7/4h8M1TLzQwiDoVdm/ot2MJQsK8vPRwnmHSxZ4ifCB0PDVqzwgVQw72D9erNnnw1/YZ0/309cD76cT5rkh47NmePLc+b4oV7B87ds8V8mgy/DCxb4L+RBedw4s1NOCZevvNLPYQnKY8cWDEzeeCM8kd3Mv5fXXguXJ00qODxz4kQfSCVIlepnmZkFV+z6858Lzoc5+GAfCAb+/ncfqAUq09DLvDwfLARf3hct8otKBIHE+vV+FbpYgcS6dX4hgCBQmjvXnx8EeUuW+LlWQf2WLT5wS8FnUKX6mFRZ6meSDOpnkgyVMehL6fgL59yVzrl5zrnvnXNXhR7b1Tn3gXNuQeg2xpgSSar/+7+Ce6jstpvfbBP8cJ6bbgoPN8rL80OHJk705R07/BDAyP1levcOD6Nr3Ng/JxgatWWLHz4VDHtbuNAPJfv2W1/etAleew1+/92X99nHD5vbdVdfXrIkPJwR4JVXoGlTPwQL/PC+Cy/01wE/FHHz5vB+NFdd5fd0CVx8ccFhbGed5YfGBU4+OTxsDfyGn5H71ZxyCvTsWeQjrZYaNvQ/r8BLLxUcVvbVV/DMM+Hy/ff7YXeByrQvTo0avs/Vru3LGRl+SGHLlr7crJnf16du3ejn77orHHxweAjgQQf584O9kPbYA444IlzfqJHvx5XpMxAREZEqoVaqXtg51wkYChwGbAf+55ybGHrsIzO7xzl3A3ADcH3sK0lCfPqpnwMVfOG++Wa/geWJJ/ryHXfAXnuFnz9/fnjOR40afk5O8OXUzM/1OeggX27a1G8Mut9+4XIwpwx8UDB3brjctauf39SihS93715wQ9W99y4YOJx5ZsGg6/DD4d57w3Oj+vf3gVijRr48aJA/Ah06lPDhiIiIiIhUHXEL+pxz+cBy4C5gtJnllnDK/sBMM9sWOv9j4CzgDKBn6DljgWko6Eu8SZP8YgbBYgBPPOHLf/qTD94mTAhP1IeCiwJAOLsB/vlNm4bLderAwIEF648+uvRtq127YoFYp07+CLRqVXCRBBERERGRNBbP4Z3TgRXAo8DPpXj+POBY51xz51wD4BRgD6C1ma0ACN3q23l5bNrkV3Tcvt2Xf/zRr/gWDJkcNQratw+vPjdrFowdGy7fey/88EM4W7f33tCgQXLfg4iIiIiIVJizyKXg43FB5xoBx5rZpFI8dzBwOZAJ/ABkAZeYWdOI52wwsyLz+pxzw4BhAK1btz50woQJ8XkDcZSZmUmjYAhhopnRdO5cNu+3H/n169P6f/9j/3//m5njxpG92260mTiR/e6/n88nTCCndWt2/fJLWk6dyi+XXUZu48a4vDwsmDskVUpS+5lUS+pjkgzqZ5IM6meSDKnqZ7169ZpjZt2i1cU96Csv59zdwDLgSqCnma1wzrUFppnZvsWd261bN5sd7J1ViUybNo2eyVrA47PPoEcPv9/SgAF+z6jZs/0iI40b+32mtm2D5s3DC0NIWkhqP5NqSX1MkkH9TJJB/UySIVX9zDkXM+gr9Zw+59wLwFgz+yiODWtlZqudc+2Bs4EjgY7AAOCe0O3b8Xq9tJKb6xdZOfRQv3LmkUf6FS1POcXXZ2T4I9CoUXjhEhERERGRJDJgE7AudKwPPVa7mCM4L9ptNrA2dK3I2+B+dui5+RGHlfK+A+oB9WMchwODK/6RJFVZFnL5I9DPObccGAe8aGY/VPD1X3fONQd2AJeb2Qbn3D3Aq6Ghn0uA8yr4GukjKwvmzPGLoNSqBfXrh5eDd67gtgEiIiIiIuWQj59ztS10ZEXcZhUqZxY6tkTcLxzk5SW43c2A5qGjPn7xkhr4IK5GjHK0+/n4oDF4r5sLlR3pHfS1Bk4HLgauAa5zzn2FX2HzZTNbV9YXN7Njojy2DjihrNeqFkaM8FsfLFvmt0cYNy7VLRIRERGRBMkDckK3sTJe+cBGwlmuwscGIBefYcmNcuQQDu6CI7scba0BNAYaRRxNgM7AroSDseBohg9EtofaFu0IdqaNdlsHaBE6modeI2V70VUBpf5szGw78BrwWig792fgIvxqnQ84597HB4DvmdmORDS22lm3Dh54wG8E3rGj3zT83HMLbocgIiIiIpWW4QOYFcDv+AUslhW6vxoffOXgg6DgtiKZsVr4gKgpPkCqFTpqh27rhW7rAA2BBlGO+hG3he8H5SDAq0c4KJPKp1wBcSgb9x/gP865PwB34Idh/hHY4Jx7GXjUzBbEraXVUXY2PPQQ7LknDBnit03Ye+9Ut0pEREQkrUVmzyLnjG0IHRuj3N+GD+4iM1fB/WjqA7uHjm74oKkOUDfiCMrBF/ZYma+mhLNeLUO3u6AgTMLKnQV1zjUFzsdn+47CD3F9C9+3BwHDnHNDzOzFijezGsnKgpdegkGDYLfdYOlSaNEi1a0SERERqRIMH4gtxS8OsTTiWHTggTTDZ9AKHzvwwdta/Pyz/BjXd/hhi03xQxSbAfvhs2V18Jm04Da4Xwc/TyoI8nYLna+gTJKlTEGfc64WcCo+0DsV/8eHmcClwAQz2xx63tXAK8BIQEFfWTz/PFx+OXTpAt27K+ATERGRamcr4eGPkbcr8dmzwvPS8kK3m/HB3dZC16uFD7Zq1K/PVvz8s5qFjgb4YCxynliLiGNXfIC3S+j5IlVJWbZs+A8+s9cc/3v3EPC8mf1c+LmhVThfAF6IV0OrjUsvha5dfcAnIiIiUoUYfuhX5AqOhY/N+FUdN+EzcpsKHStDjxfWDGiLHwZZk/ActZqEh0DuAfQB2ofuB0fr0POmzZ6tffqkWipLpm8Qfs+854HJVvKu7p8Al5SzXdXPSy/B8cdDmzZ+zz0RERGRBDJ8RmxNxLE2dLuVopmwyGNTofMij9Ku/FgfP0wy8tgDOBGfcYscCrkbPhMnIuVTlqCvrZltKu2TzWwRsKisDaqWVq+G4cNh4EB47LFUt0ZEREQquTx8gLYSvyrkyohjBbAKH3wF89VyC93mhM4vz9L8gYb4RUNaAm3wS/MHQyF3oeDS/Y0L3W9CePNtEUm8sgR9DZxzXcxsRrRK59wxwAIzWxmfplUjrVrBp5/CPvukuiUiIiKSAjn4YG156Ajmr23ALyqyPuL+BnymLZrG+ACsNT6wCoZB1ix0P9jjrGWUowU+OIu22Elw7ILP1IlI1VCWoO9+oAPQI0b9SOA3YEAF21R9zJ8PP/0EZ5zhF24RERGRKmMHPgjLCh3ZUe5vJTy/bUuh+5vxgd1yfNatsFqEFw/ZFR/MHRDxWAv8HLc2odvW+OxbvNRA2TiRdFGWoO9Y4Mli6t/Hr+IppXX77TBtGpxwAjRqlOrWiIiIVCvBXmybiR6wZeH3XltNeOjkqoj70QK14tTEZ+KCoY6N8X9NPwpoFzp2i7jfHC3pLyLxUZagryV+fm4s6/B/ZJLSevZZWLRIAZ+IiEgF7CC8CmS022DvtciFStbgv7jE2outsHqEs2p7A0eH7rfALzBSDz/csfDRkHCAVxcFcSKSGmUJ+lYBxY1BPIiy/9Grevr4Yzj8cGjQAA44INWtERERSbos/Gpvv4WOORkZfEZ4/7TI2xr4IZGRgVvksbmE16pBeM+1lviNtI8mPH8tmJ8WHJEBXIPQ8xqjgE1Eqq6yBH3vAUOdc/81s+mRFc65nsAQYEz8mpamVq6E3r3hssvgwQdT3RoREZFSy8dn1WIdWRTcj21rxP2NwGLCQd6Kwhfv2LHE129AOHBrAexDeBPtZoSX/W9a6HYXfOAnIlJdlSXo+ydwKjDVOfcB8B1+i5cuwEn4haZui3sL002bNvDuu9C5c6pbIiIiUsR6YGHoWFDodl0FrlsDvwdbR/zm2R0LHT9+/DHHHHcc+fjVIQvfNkT7tImIlFepgz4zW+2cOwy4BzgLODlUtQm/YftNZrYq7i1MJzt2QO3acNJJqW6JiIhUE9vxwdra0G0wn211lPsr8PPfAg4fqO0NnIOf01YHv6JjtKMB4TlswRGUG1B8tu1nM+pU9M2KiEhUZcn0YWargUHOucH40RUOWG1mlojGpZU1a6B7d7j/fjj33FS3RkREqohs/FCa4FiNX1EyWGGy8O1mfHAXHJnFXHtXoBXheW7HAXvhg7x9gD3x89tERKRqK1PQFwgFeavj3Jb0tmMHdO2qhVtERKoxw89zW1/MsQ6fcVuGD/LWF3O9YMGRehH3G+FXlTyQ8OIlzSOOlvhArznl/BIgIiJVTpn/vXfOHQkcip8fXXikhpnZnXFoV/pp1w7eeivVrRARkXLIIRyQrcMPgcwOPb494gjK2wo9P/LYXszr1MVn39ri9287Gr9vW3Dsjt8bqQFa/l9EREqv1EGfc64J8C7QA///jBH+/8YiHlPQF2nbNrj1Vrj+emjZMtWtERGRQvLxWbWf8QuW/Bw6VhAO1LaW8Zp18MFbkF3bBzg8orxrxG3kUb9ib0VERCSqsmT6/gV0By4GPgN+AXrjt9m5DjgYvyCXRPr0U3j0UTj1VOjVK9WtERGpFgw/vy1yAZO1he4vxwd5C/BZu0ADfJC2O9CZgkMjg6NZ6Hl1Io66hBc5qZnINyciIlJGZQn6/giMNrPxzrnmocfyzGwBfv++94EHgAHxbmSVdtJJsGiRH94pIiLllg8sAX4Avg/drqbgvnCRR34x12qKHyb5B/xS1PuE7v8BaIeGTYqISHopS9DXEpgbuh9MSYjcMuc94PaKNylN5OfT8NdfoWdPBXwiIjHk4AO0LUQP3FYQDvB+oOAwy7b4AK1R6H6jKEewkEmLiPu7ogVMRESkeinL/3tr8P9nYmZbnHPb8Ks6B4KRLgLw3HN0Gz4cunSBbt1S3RoRkaTKxM+TW4oP3FYAKyOOoLypFNdqCxwADMavSHlgqNws7q0WERFJT2UJ+r7Cz0MPfARc6ZybjZ++cEXoOQJw3nksnDuXfQ49NNUtERGJu42E58P9hg/uIo+NUc4JthJoC3TBD6tsBTShYHauMQUzdQruREREKqYsQd+zwCXOuXpmlo1fvGU68DF++sNa4O/xb2IV1aQJv597Lvs4zQwRkapjOz77tjHimN6qFTMIB3kL8f/gR2oB7AF0BI7FL4KyR+hohw/2GiW68SIiIhJVqYM+M3sHeCeiPN85tzfQCz9f/lMz2xD/JoqISEUZftXKRRHH4ojbtfhgb1u0kw84APCB3D7A2aHb4OiIthoQERGpzEoV9Dnn6gMjgalm9m7wuJltISIQFBGR5DNgM35Y5bKI28j7Syi619wu+ICtI3AYfkXLaMfCL7/k/MMOU2AnIiJSRZUq6DOzLOfcpfhF1EREJAny8FsS/I7fU67wYiirIu5nFTrX4efO7Y5f9KQ30CHiyMAHdKWRu22bAj4REZEqrCxz+r4G9ktUQ0REqoNgw/DITcODYyXhAO/3UDkvyjVa4OfItQF6RNwP5tHtjg/4aifwfYiIiEjVUZag7wbgLefcJ2b2dqIaJCJSleQB6/F72qzBZ+aCDNyqQscaYsyZC2kC7BY6Doi43y502xa/2qWCORERESmLsgR9/wA2AG8451YCv1J0RJGZWe94NU5EJJUy8f/Q/Qr8Erpdjs/QrQndrsfPqSusBtASaB06/oAP2IJNwoMjKO8K1E3cWxEREZFqrCxB3x/w322WhMq7x785IiLJlY3fhuBH4CdgPuFAb3Wh5zbFZ9xa4veZaxG6H3kbBHnN8RuYioiIiKRaWbZs6JDAdoiIJEQ2fmhlMOxyBfAz4SDvN/yeM+AXP2kP7AWcAewZOvYK3WqTcBEREamKypLpExGpVLbjhx78ig/egtvlhOfRbYlyXl1gX+BQoD9+har98XvONUh4q0VERESSq9RBn3OufWmeZ2ZLSn6WiEhsOYQzc5FZuuD2d3xwt4xwlg6gDn4rgt2Bbvg5dMFwy8j7u6OhlyIiIlJ9lCXTt4jo6xUUpu9SIlJAHrCRgtsUFF7lMvJ2U4zrNMIHb22B4/Cbiu8ZcdsOv4CKiIiIiISVJegbRNGgryb++9bF+O9qT8SpXSJSRRj+l39hoWMp4QBvA7H/YtQEn31rg18c5WTCGbnIDF0rNPRSREREpDzKspDL87HqnHP/BmYBDePQJhGphLLxC5/8EDp+JBzgRe49F/wlqD1wCAW3J4g8gkCufnKaLyIiIlJtxWUhFzPLdM6NAf6Osn0iVd4S4FPgW8JB3q+E58/VxK9o+QfgeGDviKM92jxcREREpDKJ5+qd2/FbWIlIFZKPz9rNAD4J3QarMdXCB3ZdgX7AAaFjH7SRuIiIiEhVEZegzzl3EHAlPiEgIpXYGuCr0PE5PqO3PlTXGjgGn7I/GuiMsnYiIiIiVV1Ztmz4jehrMTTFr8WQCVwSn2aJSDysAOYQDvK+wi+wEtgbvwn5MaFjL/wG5SIiIiKSPsqS6fuYokGf4RfmWwi8bGYb49QuESmHzcA0YDLwAfBz6HGHH6Z5DH5xlUPwQzabJb2FIiIiIpJsZVm9c2AC2yEi5ZALfL/LLkzHB3mf4/fEawD0BIYDhwEHAY1T1EYRERERSa14LuQiIglmwDxgSuj4GNh0yCE44FDgOvw+d0eihVZERERExCvLnL4bgNPN7KgY9Z8Ab5nZ/fFqnEh1Z8AvhIO8KfiFWMDPvzsPaPf991xx4IG0SE0TRURERKSSK0um70Lgw2LqZwIXAQr6RMrJgPnAdHwWbzqwLFTXDuiD3xevF5ARenzamjUK+EREREQkprIEfXsCPxVTPx8/hUhESsnwG6BPjzhWh+raAMeFjhPwe+NpZU0RERERKasaZXjuDvw2XrG0we/zLCIlWAKMJLzx+d+AWfhM3mj8qpvLgQnAX0LPU8AnIiIikjjjx0OHDlCjhr8dP75s9ZVZWYK+WUB/51z9whXOuYb4oZ2z4tUwkXSzDXgJOAnoANwC7I4P8haFjrHAYJTVExERkZKlKgipaHBUXH0ir11c/fjxMGwYLF4MZv522LDS11d6ZlaqAz+NKBeYC5wPHAgcAFwAfBOqO6G014vnceihh1plNHXq1FQ3QVIs28w+NrOhZraL+Q7bwcxuN7Nf4/Qa6meSaOpjkgzqZ5IMla2fjRtnlpFh5py/HTeu9PXjxpk1aGDmQxB/NGgQfk5Frl1cfbTXrV/fbNQoszVrzP7zH18uXP/kk2YbNpg9+2z0859+2uyJJ4qeW/g9lfSey1pfr57ZP/5h1qJFwceDo1Ejs+HD/W20+oyMoj/XVPUzYLbFiuViVUR9sl/MZQN+K7DgyA891r8s14rnoaBPKoN8M1tgZuPM7Aoz625mtc130gZmNsDMpppZXpxfV/1MEk19TJJB/UwSKRzA5JcruEpW8FTaACY/32y33aIHIW3bmj36aPyDpzp1zM4/P3bwk8ijRg2zAw4wq1s3en3DhmYXX1y0zcFRt67ZYYeZ1a5dvtdv3Tp2nXNF+1uVD/r8tWgEnI3fEuz60P1GZb1O6FpXA9/jtx57GagH7IrfZ3pB6LZZSddR0CepkG9m88zsHjM7xcyaW7hTNjCzY81shJm9ZmabE9gO9TNJNPUxSQb1MylOojNiseoTlVkaOTJ2INGihdmrr8bOPNWuXTSgK+3hnFmTJv62PPUlHY88Unz9Aw+U77pgds45xddnZBRf37t38Z9L27axr2sW+/ppmemL5wHsBvwG1A+VXwUGAvcCN4QeuwH4d0nXUtAnyZJtZv9nPpPXwcKdcH8zu8TMnjazuWa2I4ltUj+TRFMfk2RQP5N4ZsTq1ze7916zjz4ya948+pf1Ro3MLr88duaqdm2zmjVjBwoNGxYfPJU3q1Sa4+qrzZo1i14XK1gMjiuvLH998LOpSHBUXH0ir11SfUUD/EhVOugDTgf+U0z9Y8CpZbjebsDSUGavFvAecDJ+64e2oee0BeaXdC0FfZJIS8xsjJmdbWZBSruemZ1mPshblrKWeepnkmjqY5IM6mfpr6zZuPr1zf75z9hBW+3aZp06VSy4inXt0hzXXFN8/Q03xK5zzqxVq+h1bduazZtXcuapuCCkMgdHyc6slrW+IkN5A5Ux6HO+vmTOuRnAr2Y2IEb9c8BeZnZcqS7oz7kSv3J9FjDZzPo55zaaWdOI52wws2ZRzh0GDANo3br1oRMmTCjtyyZNZmYmjRo1SnUzpAzygcUNG/JdkyZ826QJ85o0YVW9egC0yMnhiHXrOGrdOg7esIF6+ZVjhxL1M0k09TFJBvWz9Pbhh624//59ycmpufOxOnXy6NdvMXvvvZV77tmPLVtql/GqxjHHrGXGjBZEX/PaePDBbxg5cn/WratbpLZ162wmTJjJBRccwapV9aLWAzHrSjq3pPohQ34t8pnUrZvHtdfO58QTV0f9zCLrwX+uo0fvyerVdWnVKochQ34t1bnxqI/2uoGK1Cfy2qWpj4dU/XvWq1evOWbWLWplrGiw8AGsB/5aTP3lwNoyXK8ZMAVoCdQG3gL6AxsLPW9DSddSpk8q4kczu9d85i5yAmkbMzvXzB4xs6/Nz+GrjNTPJNHUxyQZ1M+qvlhZkGXLSh5yWFxGrF27imWtKnvmKR6ZpbL8POJVL7FVxkxfWYK+rcA1xdRfDWwrw/XOA56NKF8MPIGGd0qC5ZnZZ2Z2nZn9wcIdaV8zG2xmz5vZQqu8QV5h6meSaOpjkgzqZ5VDeb/oRwtuataMPe8sMqj78svYK1HGa65VZVy9U9JXZQz6yrI5+4/AqcXU/zEUsJXWEuAI51wD55wDTgi9xjtAMIR0APB2Ga4pElUO8D4wHGgHHAU8CGQAj+Mnl/6E3yh9ALAX2hxdRESqpvJufF2azaejnZ+bC9dcA9u2FWxHXh7k5MDDD0ObNtHb2r49dO8O//43NGhQsK5BAxg5Evr1g2eegYwMcM7fPvOMfxxKrg+es2gRTJnyMYsWFayLrM/Pp0h9cXXxqBdJhlpleO4o4Enn3GjgFjNbCeCcawvcBRwH/LW0FzOzL5xzrwFf4Td2/xp4Br8lxKvOucH4wPC8MrRRBIAtwOfAdGAG8CWQje9cfYEzgVOApqlpnoiISLmNHw833wxLlvigKQiMgrphw8IBWBC4BaLV5efDIYfAlVcWDdy2bYOrroKuXWH2bLjssoLnDxwIw4fD1q3R25qV5a/bokXB14ZwUAfh9sd6X/36FR8slVQvUt2VOugzs6edcwfjF0+5xDm3HjCgOT4pMtrMnizLi5vZbcBthR7OwWf9REptAzAVH+DNwP8FIR+oCRwM/AU4ETgevxmkiIhIZVXWoG7oUFi4ENq2hWuvjR64DRsGNWtGrxswwGf2Ylm7Fjp1il6Xmwt16kDLlrBmTdH69u39bUlBXfAcBW4iiVGW4Z2Y2aVAT/zcu1nAHPzouOPMbFgxp4rE3a/Aw/hAriVwDvAU0Bi4GZiMDwZn4YdynoICPhERSY7ihlEWVx9tiOXgwT5b9uyzcMUVRQO3rCy4/XafcduyJXp7tm2LXWcGL77og8Zo2rQp2v7Cr//QQ7GHZwY0zFEkdcoU9AGY2XTze1OfYmZ9zexvZjYjEY0TiZSPH7J5E9AJP+/uamANcD3wCbAJn/G7AzgJHwCKiIiUR6LmxkWrv+QSOPZYH+AVDupycuDRR2HIENiwIXpbnYNffw1n1grLyPBHrLr+/eG++6IHbvffDxdeGPv89u1LN69ORFKnzEGfSDIFC7AMwy/lehRwL9Aan+X7BfgOv9ljD6BOSlopIiKVUXmzbUFdrMCtuLqNG+G666IPoxw6FI44wg+nLFy/Ywd89pkP8KJxzr/OHntEr2/fHjp2hLvvjp1xGzmy+GxcSYFbac5XJk+kcipT0OecO8A597RzbrZzbqFz7tdCxy+JaqhUH1uAV4E/44dtngK8DPQCXsJn9j4CrgT2TFEbRUQkPoLA6/jjjytzYFZcfXmybYMHw6BBft7Z8OHRA7dLLvHPiVbXvz80awbLl0d/r1lZ0LixX9Uymvz84rNp7dvDv/5V/sCtLKtcxlrFUtk8kSoq1l4OhQ/gSGAbsAp4Fz/a7kPgUyAP+AYYU9rrxfPQPn1V3zYzG2t+g/S65n+wLc3vmzfRzLJT17RKT/1MEk19TCqipP3P4r3xdf36Zvfea9amTfR93xo2NOvb16xOndh7x9WqVfzecsUdDzxg1rx57D3nzIrfTLxse85p37ey0r9nkgxVfZ++O4DfgX2BS0KP3W1mPfCLu3QAipnmK1LUz8A1wG74/fG+w6+0+TGwAr9v3ilA3VQ1UEREEpJtM4MbboieMbvsMr9gSaxs28CBsPfe0YdJZmX54ZUrV0Z/L1u3+lUmt2+PXu8cZGcXP/+tuLprroFHHik+G1fcMMmKZuNERKIpS9B3GPCsmW3EZ/l2nm9+IZdngTvj2jpJSzuA1/FbKOwLPIZfdGUq8BvwEHAsfrsFERFJrfIMkxw2DMaMgREjYgdtDRvCsmXRX3PzZhg3Lvbeb7m5fm5crGGS4LcQiCYjA2bNKn4YZc2axQdmFZ0bV5p6BXUiEk9lCfpqAmtD94N/wptF1P8AdI5HoyQ9/YbflDEDOBdYANwFLAVewaeLXaoaJyIiUd18c+xFSS66CC69NHr9oEGwYkX0a+bm+mxe06bR69u396tUFpdRGzeu+PqSthCoSOAWj2ycAjsRSaayBH1L8N/XMbNs/Hf1oyLqu+JXzBfZ6Sf8ypqH4BdduRPfUd7B77N3M9AmVY0TEZFizZnjM3fRZGXBp59CZmbs85s3j/54RobfBuA//4keeN19t79fUmBWkWGS8VjUREGbiFQVZQn6pgBnRpTHAX91zo12zo0BhgNvxrFtUgUZMBf4B3AAsD9wC35T9Pvwgd4k4I9o+KaISGUROScvI8Nn904+Gbp18wFRNBkZfl+44rJtJc1tKxh4WbmGQVZkmKQCNxGpLsoS9N0L3O6cqxcq345fZ+Ns/Hf4F/B7ZEs19Cu+Q+wDHAzcjd9L7zFgGfAZcC1+tR8REUm+0i62smSJz7R98QXcc48PopKxKMmUKR+XKzBT4CYiUrJapX2imS3BD/EMyjvwCy3+JQHtkipgC/Aa8DwwHT8f73h85H8G0CplLRMRkUhBYBfMvVu82M/JmzvXB2GF5+QBNGkC14f+lFu/vs/+LVni59sFAR2Eb4urVyAmIpJaZdqcXSQfP873YvxcvEH4rRVGAovxGzcORQGfiEiyFbetQrTFWLKy/Ly6zZujXy9yZU1l20REqrZSZ/qkelsGPBc6FgO7AP3xe+sdiVbdFBFJpViZvC+/hB07Yi/G4hzsvjssXVq0rn37xLVXRESSS5k+iWkH8BZwKn7Z1tvwc/bGAyuBp/HLtyrgExFJvPJk8h59FF54AerVI6r27eFf/yp+zp6IiFR9yvRJEQuBZ/Fz9VYC7YAb8UM590xds0REqq1ombwhQ2D6dL9BeXGZvA0b4NVXC54PBRdbgdhz8kREpOpTpk92+hKf1dsHv73CYfj99BbjN1FXwCciklixsnk33lg0k5ed7RdheeMNv9BKNO3bQ+3aFd/aQEREqjYFfcIXwCnA4aH7d+CXaX0bvxeH0sEiIvFR3BDNwlsnLF4MAwf650Wbcwc+gFu7FkaNKnmIpgI7EZHqS0FfNTYT6Ascgc/y3QP8ht9YvV0K2yUiUlWVNagbNsyvoPnyy3DZZUWzebm5sHIl7LJL9Ndr396/Vmn2wxMRkepLQV819DnQB7/q5mzg38Ai/P56jVPXLBGRKqG0m5wHK2j+619+7t3VVxcN6rZtgxEj4MILY2+dsH07PPGEMnkiIlJ+GrlXjeQDN+GDvBbAvcBfgEapbJSISBUSbUGVwYPho4/gtdeir6B5000lX3fuXDj9dL+QSmHt22uxFRERqRhl+qqJbOBCfMB3KT6zNwIFfCIiZRFtQZWcHBgzBrZsiX6Oc/Dhh9CmTfT6jAw46CC4++7is3nK5ImISHkp6KsG1gEnAa/gs3tPAA1T2iIRkcQqaW5drLpY9Z984hdVKW5BlVibmbdvDyec4OfulRTUaV6eiIgkgoK+NPcLfgP1WfigbwTaTF1EKr/yBGaRddEWTBk/3h9DhxaddzdmjC9HO/eii+CYY/zWCI1iDI9o3750mbqSgjpl80REJBE0py+NzQROx8/l+wjokdrmiIiUSrR5c8OG+fv9+sXeqHz+fDj8cLjqqugLpgwc6DcyNytYl5UFgwbB8OG+Pj+/YL0ZNG/ug7C3367YJuf9+imQExGR5FOmL029CfTCr8b5GQr4RKRyKS5Td/PN0YO2oUPh2GN98BZto/I774TTTvP71kWTm1s04It0zTVFA77A+vU+y6dNzkVEpCpSpi/NGPAw8Hf8ZuvvAC1T2SARkUJiZfJ+/BFq1vTlaLKyfH1ubvR652DmTDjrLFi+vGh9Rkb49aLV3XMPTJgQvT5yvp6ydSIiUtUo05dGNgN/Bq4BzgKmoIBPRFInVjYvViZv5Ei46y6oUyf69TIyYOrUcPBWWPv2cNhhcO+9sefWjRxZ/Ly7kupFRESqIgV9aWIucCjwGvAv4L9A/VQ2SESqtWgLogwZAhdcEDuT5xysWwfPPVexwKy4IZilGZ6pFTRFRCTdKOir4gx4GjgC2AZMBW5AP1gRSbxYmTwzuP766PPuXnkFasWYWNC+PTRtGp/ArLi5dSXNu9O8PBERSTeKDaqwLUA//GbrPfHZvmNS2B4RqT6iZfIGDoT994cWLeD336Of5xw8/3zJQygVmImIiMSPgr4q6hv8cM5XgLuASWj+nojEV5DJO/7443Zm8nJyYPp0uPzyopm83Fz49Vc45xxo1iz6Ndu31xBKERGRZFPQVwWNwQ/nzMQv1nIz+kGKSHTl3eS8YCbPsXgxXHwxNG4Mxx0HmzZFf70dO3wA99hjJc+7U6ZOREQkORQrVCH5+Pl6g/D77s0Fjktlg0SkUos2BHPYsFiBnb8dPBgGDPAblRfO5OXnQ7168NZbsPvu0V8z2NpA2TwREZHKQ0FfFZEFnA/8GxgO/A9oldIWiUhlUFwm78Ybo2+NMGwYnHdewb3yAjk58MILsHVr9NfLzIQzzvB72lV0Xp6IiIgkh4K+KmAV0At4HbgfeBKIsfidiKSh0g3BDGfq/vhHv1/d0qXRr7dtG/zwQ9GAL+Bcwc3IIymTJyIiUvUo6KvkfsDP3/sWH/T9HXApbZGIJFOs/e5uugmuvDJ6pu6996BuXWjSJPo1MzLg+++L3+T87ruVyRMREUkXCvoqsQ+Bo4Bs4GPgrNQ2R0RSINoQzexs+Ne//Ebm0TgHM2bA44+Xf5Pzgpk8UyZPRESkClPQV0mNBvoCewBfAN1T2xwRqYDyrKD5889w9dWxh2g6B+3aRa8r7RDM0tQvWgRTpnysTJ6IiEgVpqlhlYwBtwB3A72BV4FdUtoiEamIYHhmkK0LVtAEH0RFq7/4Yj9kslYtn3mLNveufXufkSu8GEu0IZjFBWsl1YuIiEjVp0xfJbIdGIgP+IYC76GAT6SyKE+2bvt2uPba6CtoDhkCp5wCQ4dG3xqhSROf5XvmmdIOwdRiKiIiIhKdgr5KYjNwKvACcCfwNErDiiRTcUFdSfvdvfiiD94i6y++GBo2hJUro79edjasWQNZWdHrN2+GNm1KPwRTi6mIiIhILIorKoHlwCnA98AYfLZPRJIn2hDLIUPgxx/hwAPhiiuiZ+sGDIBLL/V71xWWn++Dvrp1Ye3aovUZGTBrlg8wFy8uWh+5ZYKGYIqIiEhFKNOXYj8ARwK/4IdzDkxpa0Sqp5tuir5C5siRcOGFsGFD9PPy8nyGL5bMTHj44fKvoCkiIiISDwr6UmgG0AM/l+9j/MItIlJ+ZZl3l5EBd94Jf/0rLFkS/XrO+f3sdt89en1GBjz4YPH73VV0BU0RERGRilLQlyKvAScBrYHPgUNS2xyRKqEi8+4K1y9ZArfeCk8/XTTTFmjfHg44AO65p2LZupLm3WlenoiIiCSSgr4UWAX8GTgU+BTokNLWiFQNsYK6MWPg11/h73+PPu9u8GDo3NkvrBJt64M2bYpfIROUrRMREZGqTUFfCkwBcoGHgeapbYpIpRMrmxdt3t22bTBoEOy1F6xaFf16OTmwzz4+ixbN77+XLmhTtk5ERESqKgV9KTAVv//ewaluiEglEy2bN2gQHHVU7Hl3AM89B61aRa/LyIA33ih+3h0oaBMREZH0paAvBaYCx6H9MkQKi5bN274dvvjCb38QTUYGXHKJX1BFq2SKiIiIFKWgL8mWAguBXqluiEiKFB6+OW4cfP45XH997GyeWfQFVzTvTkRERKRkKQv6nHP7OufmRhybnXNXOed2dc594JxbELptlqo2JsLU0K2CPklXZV1h86KL/PDNBx+EevWiX7M0Wx+A5t2JiIiIRJOyoM/M5ptZVzPril/IchvwJnAD8JGZ7QN8FCqnjanArkCXVDdEpJzKGtQNGgSnn+4DrMGDo6+g2aIFrFkDo0dXbOsDERERESmqskwrOwH4xcwWO+fOAHqGHh8LTAOuT1G74srwK3f2RONqpWoKgrogcFu82M+nGzPGZ+kmT4YdOwqes307vPsu7LmnX0kzmnXroGnTcBB3881+qGf79j7gU3AnIiIiUn6VJfa4AHg5dL+1ma0ACN3GWJOv6vkNWIKGdkrlFy2bt2MHXHNN0Uzdjh0wdSosX1404As4B7/8UvIKmqBsnoiIiEi8OTNLbQOcqwMsBw40s1XOuY1m1jSifoOZFZnX55wbBgwDaN269aETJkxIVpNLLTMzk0aNGu0sT2zThvv3248xX35Jh2hj3ETKoXA/q6gPP2zF/ffvS05OzZ2P1aiRT506+WRnRx8c4JwxZcrHXHDBEaxaVXRiXuvW2UyYMDPqtevWzePaa+dz4omr4/YeJL7i3cdEolE/k2RQP5NkSFU/69Wr1xwz6xatrjIEfWcAl5vZyaHyfKCnma1wzrUFppnZvsVdo1u3bjZ79uwktLZspk2bRs+ePXeW+wMfAisAl6I2Sfop3M8qKiMj+iqaDRr4bRPWrIl+zqJFRYd/BudFLrgyfryGb1Y18e5jItGon0kyqJ9JMqSqnznnYgZ9lWF4558JD+0EeAcYELo/AHg76S1KgMj5fAr4JNWiDd9ctw4eeST2tglZWfDQQxXbNiF4joZvioiIiCRPShdycc41AE4Chkc8fA/wqnNuMH4K3HmpaFu8/YzP8B2f6oZItRdtMZYBoT+z5OVBnTp+8ZXCgm0ToPhMXb9+CuREREREKpOUZvrMbJuZNTezTRGPrTOzE8xsn9Dt+lS2MV60P58kU3HbKtx0U9HFWPLyfMbum2/guee0bYKIiIhIOqksWzakvSnAbsDeqW6IpL1ombwhQ+CDD2DDhtjDNzMzoUsXf4Dm3YmIiIikCwV9SWD4zQb7oPl8kng331w0k5edDWPHQseO0KiRD/AKK7xtgoI8ERERkfRQGRZySXvfA2vQ0E5JPLPYmbxgr7ynnip++KaIiIiIpBcFfUkwJXSroE/iKZi3d/zxx5GR4TdOP+ooH/hF0769D/xKs8KmiIiIiKQPDe9MgqlAR6BDitsh6aPgvD3HkiV+O4UWLWDgQHjlFb/FQqBwJk/DN0VERESqD2X6EiwP+Bhl+aTsYq3AuW4dXHVV0Xl74IO7MWNg1Chl8kRERETEU6Yvwb4BNqCgT8om2gqcAwfCP/7ht0mINYRz6VJ/q0yeiIiIiASU6Usw7c8nscTK5JnBddcVzeTl5sLy5XDbbdCmTfRrRq7AKSIiIiICCvoSbirwB/wefSKBIJO3eLEP8hYvhsGD4YQTYK+9fHAXzfbtPui7/36twCkiIiIipaOgL4HynGM6yvJJUdH20svJgalToXNnaNYs+nlBJq/gCpymeXsiIiIiEpOCvgSa36gRW4DjU90QqVSK20sP4O234bHHSs7k9evn5/dNmfIxixYp4BMRERGR6BT0JdDcULqmZ2qbISlUeN7erbfCsccWv5ceaC89EREREYkfrd6ZQF83bcqBQKtUN0RSItoKnHfeCbvs4lfifPXVgkM8tZeeiIiIiCSCMn0Jsh2Y16SJhnamuVgrcAJcf330vfSaNPF76SmTJyIiIiLJoExfgnwJZNesqUVc0li0TN6gQfDcc7BsGfz+e/Tzli3zt8rkiYiIiEgyKNOXIFMBZ8ZxqW6IJEy0FTi3b/crcO69NzRtGv087aUnIiIiIsmkoC9BpgB7Z2aya6obIgnx228+sxfLxInwn/9oLz0RERERST0FfQlyPTBg0aJUN0MqqPCcvXvugf79YZ99Yp+jFThFREREpDLRnL4E6QPUW7cu1c2QCog2Z+/GG6FOHbjqKh8EFl6sRStwioiIiEhlo6BPJIZoc/YAWrWC++/395s1889bssRn+EaOVJAnIiIiIpWLgj6RGJYsif545KqcyuSJiIiISGWnoE+kEDN48kl/G41W3xQRERGRqkQLuUi1F7lYS/v2cMQRcPnl0KUL1K9f8LlafVNEREREqhoFfVKtBYu1LF7sM3tLl8KXX8IFF8DXX8OoUVp9U0RERESqNg3vlGot1mItn3/uM3+asyciIiIiVZ0yfZL2Cu+1N368z+p98UXsDdZjLeIiIiIiIlLVKOiTtFZ4+ObixXDJJdCunZ+751z087RYi4iIiIikCwV9ktaiDd/csQM2bIDRo/0cvQYNCtZrsRYRERERSSea0ydpKzs79vDN7dth8GB/v359bbAuIiIiIulLmT6p8grP2Rs9Gu67D/bcM/Y5kcM3+/WDRYsgP9/fKuATERERkXSiTJ9UacGcvWAI5+LFMHSov3/iiTBwIDzySMEhnhq+KSIiIiLViYI+qdJibbnQpg188IG/f+CBGr4pIiIiItWXgj6pEsaPLxi43X471KwZe87eqlXh+9prT0RERESqMwV9UulFG8J5ySX+fq1akJtb9BxtuSAiIiIi4mkhF6n0brop+hDOVq3g+ee15YKIiIiISHEU9EmlUHgFzvHjYcsWeOwxP6QzmjVr/LDNZ56BjAy/0XpGhi9rOKeIiIiIiKfhnZJy0YZvDhzo5+zl5ECdOn5fvcKCIZyasyciIiIiEpsyfZJy0VbgzM31Qd8XX8Bzz2kIp4iIiIhIeSnok5SLNXwzKwsOO0xDOEVEREREKkLDOyWlXn/dB3JmResiV+DUEE4RERERkfJRpk+SovBCLY8/DmefDeeeC3vsAfXqFXy+hm+KiIiIiMSHgj5JuGChlsWLfUZv8WL461/h3Xfh3/+GhQth9GgN3xQRERERSQQN75SEi7ZQC/h99q67zt/X8E0RERERkcRQpk8SLtZCLStWJLcdIiIiIiLVkYI+SbhmzaI/HrlQi4iIiIiIJIaCPkmYHTvg8sth/Xq/gEskLdQiIiIiIpIcCvokIdatg9694Ykn4Npr4fnntVCLiIiIiEgqaCEXiYvx4/2CLUuWQJs2kJcHGzf6YG/AAP+ciy5KZQtFRERERKonBX1SYcGWDMEKncECLbfdFg74REREREQkNTS8U0qt8Abr48fDhg1w9dXRt2R4/vkkN1BERERERIpQpk9KpXA2b/FiP1zTLPY5sbZqEBERERGR5Elpps8519Q595pz7ifn3I/OuSOdc7s65z5wzi0I3cZY8F+SKdoG62bQpAm0bh39HG3JICIiIiKSeqke3vkI8D8z2w84CPgRuAH4yMz2AT4KlSXFYmXtNm+GBx7wWzBE0pYMIiIiIiKVQ8qCPufcLsCxwLMAZrbdzDYCZwBjQ08bC5yZivZJ2KRJsYdxtm/vt1545hltySAiIiIiUhmlck7fnsAaYIxz7iBgDnAl0NrMVgCY2QrnXKsUtrHae/VVH7xlZMDq1ZCVFa6LzOb166cgT0RERESkMnJW3EociXxh57oBM4EeZvaFc+4RYDNwhZk1jXjeBjMrMq/POTcMGAbQunXrQydMmJCchpdBZmYmjRo1SnUzym3ixDY8+OC+HHjgJu6++ztmzmzO6NF7snp1XVq1ymHIkF858cTVqW5mtVfV+5lUfupjkgzqZ5IM6meSDKnqZ7169ZpjZt2i1aUy6GsDzDSzDqHyMfj5e3sDPUNZvrbANDPbt7hrdevWzWbPnp3oJpfZtGnT6NmzZ6qbUWqRG6w3beq3Y+jTB15/veicPak8qlo/k6pHfUySQf1MkkH9TJIhVf3MORcz6EvZnD4zWwksdc4FAd0JwA/AO0CwpfcA4O0UNK/aCbZkWLzYz9/bsAFq1oQLLlDAJyIiIiJSlaV6n74rgPHOuTrAr8Al+ED0VefcYGAJcF4K21dtRNuSIS8PbrsNBgyIfo6IiIiIiFR+KQ36zGwuEC0FeUKSm1LtxdqSQRusi4iIiIhUbanep08qgdzc2EM4tcG6iIiIiEjVpqCvmtuxw2+1sHUr1K5dsE4brIuIiIiIVH0K+qqxnBw491y/F9/998OYMdpgXUREREQk3aR6IRdJosgtGXbfHZo0gXnz4PHH4bLL/HMU5ImIiIiIpBcFfdVEsCVDsELn0qX+GDo0HPCJiIiIiEj60fDOaiLalgwAkycnvy0iIiIiIpI8CvqqCW3JICIiIiJSPWl4ZzXRpg2sWFH0cW3JICIiIhJfO3bsYNmyZWRnZ6e6KZICTZo04ccff0zY9evVq8fuu+9O7cJL7xdDQV81MHkyrF/vV+U0Cz+uLRlERERE4m/ZsmU0btyYDh064JxLdXMkybZs2ULjxo0Tcm0zY926dSxbtoyOHTuW+jwN70xzY8fCqafCvvvCo49qSwYRERGRRMvOzqZ58+YK+CTunHM0b968zFlkZfrSTOS2DLvsAps2wYknwuuv+/Jf/5rqFoqIiIikPwV8kijl6VvK9KWRYFuGxYv9MM5Nm6BmTejf3wd8IiIiIpL+Nm7cyBNPPFHm80455RQ2btwY/wZJyinoSyPRtmXIy4PbbktNe0REREQk+WIFfXl5ecWeN2nSJJo2bZqgVkkqaXhnGtG2DCIiIiJyww038Msvv9C1a1dq165No0aNaNu2LXPnzuWHH37gzDPPZOnSpWRnZ3PllVcybNgwADp06MDs2bPJzMykb9++HH300Xz22WfstttuvP3229SvXz/F70zKS0FfGmnVClatKvq4tmUQERERSY2rgLlxvmZX4OFi6u+55x7mzZvH3LlzmTZtGqeeeirz5s3budrjc889x6677kpWVhbdu3fnnHPOoXnz5gWusWDBAl5++WVGjRrFn/70J15//XX69+8f53ciyaKgL01s2gS5udqWQUREREQKOuywwwos7//oo4/y5ptvArB06VIWLFhQJOjr2LEjXbt2BeDQQw9l0aJFyWquJICCvjRgBpdeChs3+vl7Y8b4IZ3t2/uAT9syiIiIiKTGw6luANCwYcOd96dNm8aHH37I559/ToMGDejZs2fU5f/r1q27837NmjXJyspKSlslMRT0pYEXX4QJE+DOO+GWW7Rwi4iIiEh11rhxY7Zs2RK1btOmTTRr1owGDRrw008/MXPmzCS3TlJBQV8Vt3AhXH45HHMM3HhjqlsjIiIiIqnWvHlzevToQadOnahfvz6tW7feWdenTx+eeuopunTpwr777ssRRxyRwpZKsijoq8J27IALL4RatWDcOL8nn4iIiIjISy+9FPXxunXr8v7770etC+bttWjRgnnz5u18/Nprr417+yS5FPRVYbffDrNmwX//qxU6RUREREQkOgV9Vcz48X4T9iVL/AIuxx0H556b6laJiIiIiEhlVSPVDZDSGz8ehg2DxYvD2zJ8+aV/XEREREREJBoFfVXIzTfDtm0FH8vK8o+LiIiIiIhEo6CvClmypGyPi4iIiIiIKOirIrZuhTp1otdpERcREREREYlFQV8VsGULnHIK5OQUDfwaNICRI1PTLhERERGpfDZu3MgTTzxRrnMffvhhthWeTyRVnoK+Sm7zZujTBz79FF5+GZ57DjIywDl/+8wz0K9fqlspIiIiIuU1fjx06AA1avjbii7Sp6BPCtOWDZVM5JYMu+0Gdev61TonTAhvzaAgT0RERCQ9BKuzB3HW4sW+DOX/znfDDTfwyy+/0LVrV0466SRatWrFq6++Sk5ODmeddRb//Oc/2bp1K3/6059YtmwZeXl5/OMf/2DVqlUsX76cXr160aJFC6ZOnRqfNykpp6CvEin8S79smb+96irtxSciIiJSFV11FcydG7t+5kw/hSfStm0weDCMGhX9nK5d4eGHY1/znnvuYd68ecydO5fJkyfz2muv8eWXX2JmnH766UyfPp01a9bQrl07Jk6cCMCmTZto0qQJDz74IFOnTqVFixZleJdS2Wl4ZyUSbUsGgDffTH5bRERERCTxCgd8JT1eVpMnT2by5MkcfPDBHHLIIfz0008sWLCAzp078+GHH3L99dczY8YMmjRpEp8XlEpJmb5KRFsyiIiIiKSX4jJy4OfwLV5c9PGMDJg2reKvb2bceOONDB8+vEjdnDlzmDRpEjfeeCMnn3wyt956a8VfUColZfoqkVhbL2hLBhEREZH0NHKkX409UkVXZ2/cuDFbtmwBoHfv3jz33HNkZmYC8Pvvv7N69WqWL19OgwYN6N+/P9deey1fffVVkXMlfSjTV4lccw1ceWXBx7Qlg4iIiEj6ChZrCRbya9/ef/eryMJ9zZs3p0ePHnTq1Im+ffty4YUXcuSRRwLQqFEjxo0bx8KFCxkxYgQ1atSgdu3aPPnkkwAMGzaMvn370rZtWy3kkkYU9FUS+fnwzjt+H74WLWDFivj80ouIiIhI5davX/y/77300ksFylcWyizstdde9O7du8h5V1xxBVdccUV8GyMpp6CvkvjPf+Cjj/y+e0OHpro1IiIiIiKSLjSnrxL46Se4/no49VQYMiTVrRERERERkXSioC/FduyAiy6Chg1h9GhwLtUtEhERERGRdKLhnSl2990wezb897/Qpk2qWyMiIiIiIulGQV8KjB8fXqHJDI46Cs49N9WtEhERERGRdKThnUk2fjwMG+Y34TTzj339tX9cREREREQk3hT0JdnNN8O2bQUfy8ryj4uIiIiIVNTGjRt54oknyn3+ww8/zLbCX1hLMGPGDA488EC6du1KVlZWuV+7LE455RQ2btyYkGvPnj2bv/3tbwm5dioo6EuyJUvK9riIiIiISFmkIugbP3481157LXPnzqV+/fplfs28vLwynzNp0iSaNm1a5vNKo1u3bjz66KMJuXYqKOhLEjN44YXYq3O2b5/c9oiIiIhIerrhhhv45Zdf6Nq1KyNGjADgvvvuo3v37nTp0oXbbrsNgK1bt3Lqqady0EEH0alTJ1555RUeffRRli9fTq9evejVq1eRa3/00UccfPDBdO7cmUGDBpGTk8Po0aN59dVXueOOO+hXaJf5RYsWsd9++zFgwAC6dOnCueeeuzOg7NChA3fccQdHH300//3vf5k8eTJHHnkkhxxyCOeddx6ZmZm8//77/OlPf9p5vWnTpvHHP/5x5/lr164F4MEHH6RTp0506tSJhx9+eOdrd+rUaee5999/P7fffjsAjz76KAcccABdunThggsuKPI+p02bxmmnnQbA7bffzoABAzj55JPp0KEDb7zxBtdddx2dO3emT58+7NixA4A77riD7t27c/jhhzNs2DAsNJdr1qxZdOnShSOPPJIRI0bsbFNeXh4jRozY+XN5+umnAVixYgXHHnssXbt2pVOnTsyYMaNUP/fiKOhLgPHjoUMHOP744+jQAR5+GPr0gQEDYK+9oF69gs9v0ABGjkxBQ0VEREQk8Xr2hOef9/d37PDlceN8eds2X37lFV/etMmX33jDl9eu9eV33/XllStLfLl77rmHvfbai7lz53LfffcxefJkFixYwJdffsncuXOZM2cO06dP53//+x/t2rXjm2++Yd68efTp04e//e1vtGvXjqlTpzJ16tQC183OzmbgwIG88sorfPfdd+Tm5vLkk08yZMgQTj/9dO677z7GR1moYv78+QwbNoxvv/2WXXbZpUAWsl69enzyySeceOKJ3HXXXXz44Yd89dVXdOvWjQcffJCTTjqJmTNnsnXrVgBeeeUVzj///ALXnzNnDmPGjOGLL75g5syZjBo1iq+//rrEz+jrr7/m22+/5amnnirxM/3ll1+YOHEib7/9Nv3796dXr15899131K9fn4kTJwLw17/+lVmzZvHFF1+QlZXFe++9B8All1zCU089xeeff07NmjV3XvPZZ5+lSZMmzJo1i1mzZjFq1Ch+++03XnrpJXr37s3cuXP55ptv6Nq1a4ntK4mCvjgruFCLY/FiuPpqmDYNHnvMb8Q+ejRkZPisX0YGPPMMFPqjiIiIiIhIXEyePJnJkydz8MEHc8ghh/DTTz+xYMECOnfuzIcffsj111/PjBkzaNKkSbHXmT9/Ph07duQPf/gDAAMGDGD69Oklvv4ee+xBjx49AOjfvz+ffPLJzroggJs5cyY//PADPXr0oGvXrowdO5bFixdTq1Yt+vTpw7vvvktubi4TJ07kjDPOKHD9Tz75hLPOOouGDRvSqFEjzj777BKzY126dKFfv36MGzeOWrVK3tCgb9++1K5dm86dO5OXl0efPn0A6Ny5M4sWLQJg6tSpHH744RxxxBFMmTKF77//no0bN7JlyxaOOuooAC688MKd15w8eTIvvPACXbt25fDDD2fdunUsWLCA7t27M2bMGG6//Xa+++47GjduXGL7SqItG+Is2kItAC1bwl//6u/366cgT0RERKTamDYtfL927YLlBg0Klps0KVhu0aJguRwbO5sZN954I8OHDy9SN2fOHCZNmsSNN97IySefzK233lrsdcrDFZrfFFlu2LDhzmufdNJJvPzyy0XOP//883n88cfZdddd6d69e5EgKFa7atWqRX5+/s5ydnb2zvsTJ05k+vTpvPPOO9x55518//33xQZ/devWBaBGjRrUrl1753uoUaMGubm5ZGdnc9lllzF79myaNm3KAw88QHZ2drGfmZnx2GOP0bt37yJ106dPZ+LEiVx00UWMGDGCiy++OOZ1SkOZvjiLtSDL8uXJbYeIiIiIVE+NGzdmy5YtO8u9e/fmueeeIzMzE4Dff/+d1atXs3z5cho0aED//v259tpr+eqrr6KeH9hvv/1YtGgRCxcuBODFF1/kuOOOK7E9S5Ys4fPPPwfg5Zdf5uijjy7ynCOOOIJPP/1057W3bdvGzz//DEDPnj356quvGDVqVJGhnQDHHnssb731Ftu2bWPr1q28+eabHHPMMbRu3ZrVq1ezbt06cnJydg63zM/PZ+nSpfTq1Yt7772XjRs37vxsyisIKFu0aEFmZiavvfYaAM2aNaNx48bMnDkTgAkTJuw8p3fv3jz55JM75wT+/PPPbN26lcWLF9OqVSuGDh3K4MGDd/5cKkKZvjhr394P7Yz2uIiIiIhIojVv3pwePXrQqVMn+vbty3333cePP/7IkUceCUCjRo0YN24cCxcuZMSIETuzV08++SQAw4YNo2/fvrRt27bAvL569eoxZswYzjvvPHJzc+nevTuXXnppie3Zf//9GTt2LMOHD2efffbhL3/5S5HntGzZkueff54///nP5OTkAHDXXXfxhz/8gZo1a3Laaafx/PPPM3bs2CLnHnLIIQwcOJDDDjsMgCFDhnDwwQcDcOutt3L44YfTsWNH9ttvP8AvoNK/f382bdqEmXH11VdXeBXQpk2bMnToUDp37swee+xB9+7dd9Y9++yzDB06lIYNG9KzZ8+dw2iHDBnCokWLOOSQQzAzWrZsyVtvvcW0adO47777qF27No0aNeKFF16oUNsAXHnTtJVJt27dbPbs2aluBhCe0xc5xLNBA83bk8SZNm0aPXv2THUzJI2pj0kyqJ9JMiSrn/3444/sv//+CX+dqmDRokWcdtppzJs3L9VNSZotW7YUGIKamZlJo0aNAL+AzIoVK3jkkUcq9BrR+phzbo6ZdYv2fA3vjLN+/XyA5xdqMS3UIiIiIiJSjU2cOLHA9gu33HJL0tuQ0uGdzrlFwBYgD8g1s27OuV2BV4AOwCLgT2a2IVVtLI9goZZp0z7WXy1FREREpNrq0KFDtcryRXP++edHnYuYTJUh09fLzLpGpCJvAD4ys32Aj0JlERERERERKYfKEPQVdgYQzNAcC5yZuqaIiIiIiJRdOqybIZVTefpWqoM+AyY75+Y454aFHmttZisAQretUtY6EREREZEyqlevHuvWrVPgJ3FnZqxbt4569eqV6byUrt7pnGtnZsudc62AD4ArgHfMrGnEczaYWbMo5w4DhgG0bt360Mg9LyqLyJV6RBJF/UwSTX1MkkH9TJIhWf3MOUfDhg2pWbNmwl9LKh8zK7IhfTzl5eWxdevWIn9U6NWrV8zVO1O6kIuZLQ/drnbOvQkcBqxyzrU1sxXOubbA6hjnPgM8A37Lhsq4YIqWn5ZkUD+TRFMfk2RQP5NkUD+TZKiM/Sxlwzudcw2dc42D+8DJwDzgHWBA6GkDgLdT00IREREREZGqL5WZvtbAm6HUZy3gJTP7n3NuFvCqc24wsAQ4L4VtFBERERERqdJSFvSZ2a/AQVEeXweckPwWiYiIiIiIpJ+ULuQSL865NcDiVLcjihbA2lQ3QtKe+pkkmvqYJIP6mSSD+pkkQ6r6WYaZtYxWkRZBX2XlnJsdawUdkXhRP5NEUx+TZFA/k2RQP5NkqIz9LNX79ImIiIiIiEgCKegTERERERFJYwr6EuuZVDdAqgX1M0k09TFJBvUzSQb1M0mGStfPNKdPREREREQkjSnTJyIiIiIiksYU9CWAc66Pc26+c26hc+6GVLdH0oNzbg/n3FTn3I/Oue+dc1eGHt/VOfeBc25B6LZZqtsqVZtzrqZz7mvn3HuhsvqYxJ1zrqlz7jXn3E+hf9eOVF+TeHLOXR36/3Kec+5l51w99TGpKOfcc8651c65eRGPxexXzrkbQzHBfOdc79S0WkFf3DnnagKPA32BA4A/O+cOSG2rJE3kAn83s/2BI4DLQ33rBuAjM9sH+ChUFqmIK4EfI8rqY5IIjwD/M7P9gIPwfU59TeLCObcb8Degm5l1AmoCF6A+JhX3PNCn0GNR+1Xoe9oFwIGhc54IxQpJp6Av/g4DFprZr2a2HZgAnJHiNkkaMLMVZvZV6P4W/Bek3fD9a2zoaWOBM1PSQEkLzrndgVOB0REPq49JXDnndgGOBZ4FMLPtZrYR9TWJr1pAfedcLaABsBz1MakgM5sOrC/0cKx+dQYwwcxyzOw3YCE+Vkg6BX3xtxuwNKK8LPSYSNw45zoABwNfAK3NbAX4wBBolcKmSdX3MHAdkB/xmPqYxNuewBpgTGgo8WjnXEPU1yROzOx34H5gCbAC2GRmk1Efk8SI1a8qTVygoC/+XJTHtESqxI1zrhHwOnCVmW1OdXskfTjnTgNWm9mcVLdF0l4t4BDgSTM7GNiKhtlJHIXmVJ0BdATaAQ2dc/1T2yqphipNXKCgL/6WAXtElHfHDycQqTDnXG18wDfezN4IPbzKOdc2VN8WWJ2q9kmV1wM43Tm3CD80/Xjn3DjUxyT+lgHLzOyLUPk1fBCovibxciLwm5mtMbMdwBvAUaiPSWLE6leVJi5Q0Bd/s4B9nHMdnXN18JM330lxmyQNOOccfv7Lj2b2YETVO8CA0P0BwNvJbpukBzO70cx2N7MO+H+7pphZf9THJM7MbCWw1Dm3b+ihE4AfUF+T+FkCHOGcaxD6//ME/Fx49TFJhFj96h3gAudcXedcR2Af4MsUtE+bsyeCc+4U/LyYmsBzZjYytS2SdOCcOxqYAXxHeL7VTfh5fa8C7fH/yZ1nZoUnGIuUiXOuJ3CtmZ3mnGuO+pjEmXOuK37BoDrAr8Al+D9Gq69JXDjn/gmcj1/9+mtgCNAI9TGpAOfcy0BPoAWwCrgNeIsY/co5dzMwCN8PrzKz95PfagV9IiIiIiIiaU3DO0VERERERNKYgj4REREREZE0pqBPREREREQkjSnoExERERERSWMK+kRERERERNKYgj4REREREZEUcM4tcs59mOjXUdAnIiIiIiKSxhT0iYiIiIiIpDEFfSIiIiIiImlMQZ+IiIiIiKQt51xr59xTzrnfnXPbnXMLnXM3OudqhOo7OOfMOXeLc254qD7bOfe1c+7kKNfbwzk3zjm3JvS8b5xzA6M8z4WuN8c5t805t8E594lz7owoz+3unPvUOZflnFvqnLsmynPOcc594Zzb5JzbGmrnk6X6DMysVB+WiIiIiIhIVeKcawHMAuoBzwDLgR7ARcDTZnapc64D8BvwDdAaeALIBoYD7YHjzeyTiOt9DTQHHgN+B/4UuuYIM7s/4rWfCl1jGjAR2A50B7aY2WWh5ywKPb4L8CLwK3A+cBzQx8z+L/S8E4APQtd6A9gB7An0NbMuJX4OCvpERERERCQdOeeeBs4BOpvZiojH7wZuAPbDB12/AbnAgWb2c+g5LYEFwI9mdmTosfuBv1MwIKsNfAwcDOxuZuucc8eGHnseGGQRQZdzzgXlUNCXgQ/e/hd6rC6wBJhuZueFHnsIGATsamZ5Zf0cNLxTRERERETSjnPOAecBk4AdzrkWwQH8H+CAXhGnTAoCPgAzWwOMB45wzjUPPXwaMC8I+ELP2wE8hM8mnhB6+LzQ7c1WKMtWuAwsCgK+UH0OMBOfyQtsBBoCfUPvq0wU9ImIiIiISDpqCTTDD+VcU+iYFnpOq4jnz49yjeCxDhG3P0Z53g+h246h272B9Wa2vBTtXBTlsQ3ArhHlJ0Kv8S6wwjn3snPuz6EsY4lqleZJIiIiIiIiVUyQ4HoFGB3jOb9G3I827620WbXgeRZRLu08uljDNXe+tpmtcc4dAhwP9AFOBi4ARjjnjjazbcW9gII+ERERERFJR2uAzUAdM/sw1pNCC7mAn99X2B9Ct4tDt4tiPG+/iHrwcwF7O+d2M7PfS9/k2MwsF5gcOnDO/QWfATwPGFvcuRreKSIiIiIiaSe04Ml/gdOdc90L1zvnGocWTQmc4pz7Q0R9S+BC4AszWxt6+F2gs3PupIjn1QKuwq/4GQSX/w3d3lV4Dl555uRFzCmM9HXotmlJ5yvTJyIiIiIi6epGoCcwwzn3LPAt0Bg4EDgX6Bzx3O+Bj51zjwM5+O0WGgHXRTzn3/hhlW8554ItG84jvGXDegAzm+6cGw0MATo4597FrxJ6KLANuLyM72O0c64V8BF+Zc8WwKXAVuCdkk5W0CciIiIiImkpNBfucOAW4AxgKH4lzAXAncBKoE3o6a/hh4SOAPbAL9jyRzObHnG9tc65HsC/8AFdY/xiL4PMbEyhlx8GzA3d3o0P9r4H7i3HWxkHDA61f1dgLfA5cKeZ/VbSydqnT0REREREqq2Izdn/YWZ3pbg5CaE5fSIiIiIiImlMQZ+IiIiIiEgaU9AnIiIiIiKSxjSnT0REREREJI0p0yciIiIiIpLGFPSJiIiIiIikMQV9IiIiIiIiaUxBn4iIiIiISBpT0CciIiIiIpLGFPSJiIiIiIiksf8H1STAO9HDNM8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "curve_graph(parametr_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
